{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Dask dataframes on HDFS\n","\n","To use Dask dataframes in parallel across an HDFS cluster to read CSV data. We can coordinate these computations with [distributed](http://distributed.dask.org/en/latest/) and dask.dataframe.\n","\n","As Spark, Dask can work in cluster mode. You can use the dask module [dask_jobqueue](https://jobqueue.dask.org/en/latest/) to launch a Dask cluster with the job manager SLURM."]},{"cell_type":"markdown","metadata":{},"source":["```py\n","from dask_jobqueue import SLURMCluster\n","\n","cluster = SLURMCluster(cores=16,\n","                       queue='test',\n","                       project='myproject',\n","                       memory=\"16GB\",\n","                       walltime=\"01:00:00\")\n","```"]},{"cell_type":"markdown","metadata":{},"source":["The cluster generates a traditional job script and submits that an appropriate number of times to the job queue. You can see the job script that it will generate as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(cluster.job_script())"]},{"cell_type":"markdown","metadata":{},"source":["Access to the cluster using following lines:\n","\n","```\n","import dask.dataframe as dd\n","from dask.distributed import Client\n","client = Client(cluster)\n","```\n","\n","`nyc2014` is a dask.dataframe objects which present a subset of the Pandas API to the user, but farm out all of the work to the many Pandas dataframes they control across the network.\n","\n","```python\n","nyc2014 = dd.read_csv('/opt/datasets/nyc-data/2014/yellow*.csv',\n","parse_dates=['pickup_datetime', 'dropoff_datetime'],\n","skipinitialspace=True)\n","nyc2014 = c.persist(nyc2014)\n","progress(nyc2014)\n","```"]},{"cell_type":"markdown","metadata":{},"source":["### Exercises \n","\n","- Display head of the dataframe\n","- Display number of rows of this dataframe.\n","- Compute the total number of passengers.\n","- Count occurrences in the payment_type column both for the full dataset, and filtered by zero tip (tip_amount == 0).\n","- Create a new column, tip_fraction\n","- Plot the average of the new column tip_fraction grouped by day of week.\n","- Plot the average of the new column tip_fraction grouped by hour of day.\n","\n","[Dask dataframe documentation](http://docs.dask.org/en/latest/dataframe.html)"]}],"metadata":{"kernelspec":{"display_name":"big-data","language":"python","name":"big-data"},"deepnote_notebook_id":"379fcb20-a410-4e6b-9597-3e0eecd8481f"},"nbformat":4,"nbformat_minor":4}