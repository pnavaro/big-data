{"cells":[{"cell_type":"markdown","source":"# Parallel Computation\n\nThis notebook objective is to learn how to parallelize application with Python\n\n## Parallel computers\n- Multiprocessor/multicore: several processors work on data stored in shared memory\n- Cluster: several processor/memory units work together by exchanging data over a network\n- Co-processor: a general-purpose processor delegates specific tasks to a special-purpose processor (GPU)","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00000-7f5358b0-f5e4-4239-b111-a84cac89d008"}},{"cell_type":"markdown","source":"## Parallel Programming\n- Decomposition of the complete task into independent subtasks and the data flow between them.\n- Distribution of the subtasks over the processors minimizing the total execution time.\n- For clusters: distribution of the data over the nodes minimizing the communication time.\n- For multiprocessors: optimization of the memory access patterns minimizing waiting times.\n- Synchronization of the individual processes.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00001-c89520b2-79d7-41b1-bc94-bef944269719"}},{"cell_type":"markdown","source":"## MapReduce","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00002-8ed39e2b-06d6-4b45-a07b-93c7426d8866"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00003-a6d0d1b5-7958-41b2-86cf-215e54f2567e","output_cleared":false},"source":"from time import sleep\ndef f(x):\n    sleep(1)\n    return x*x\nL = list(range(8))\nL","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"[0, 1, 2, 3, 4, 5, 6, 7]"},"metadata":{}}]},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00004-0368a8cd-8a8e-46e5-86ac-690071ddedd7","output_cleared":false},"source":"%time sum(f(x) for x in L)","execution_count":null,"outputs":[{"name":"stdout","text":"CPU times: user 863 µs, sys: 703 µs, total: 1.57 ms\nWall time: 8.01 s\n","output_type":"stream"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"140"},"metadata":{}}]},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00005-f2152918-0d12-4c04-9c6d-998ff31bda75","output_cleared":false},"source":"%time sum(map(f,L))","execution_count":null,"outputs":[{"name":"stdout","text":"CPU times: user 1.34 ms, sys: 1.12 ms, total: 2.47 ms\nWall time: 8.01 s\n","output_type":"stream"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"140"},"metadata":{}}]},{"cell_type":"markdown","source":"## Multiprocessing \n\n`multiprocessing` is a package that supports spawning processes.\n\nWe can use it to display how many concurrent processes you can launch on your computer.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00006-90276e80-5472-4382-921f-9f1cd0c80459"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00007-54f6b4f2-bf5a-4f94-9ec6-2d31b317dcfe","output_cleared":false},"source":"from multiprocessing import cpu_count\n\ncpu_count()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"markdown","source":"## Futures\n\nThe `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n\nThe asynchronous execution can be performed with:\n- **threads**, using ThreadPoolExecutor, \n- separate **processes**, using ProcessPoolExecutor. \nBoth implement the same interface, which is defined by the abstract Executor class.\n\n`concurrent.futures` can't launch **processes** on windows. Windows users must install \n[loky](https://github.com/tomMoral/loky).","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00008-5e980cdb-7f76-4364-93a0-d4eb3f5a77a0"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00009-505b529f-4676-497f-8bfb-4c7725e792bf","output_cleared":false},"source":"%%file pmap.py\nfrom concurrent.futures import ProcessPoolExecutor\nfrom time import sleep, time\n\ndef f(x):\n    sleep(1)\n    return x*x\n\nL = list(range(8))\n\nif __name__ == '__main__':\n    \n    begin = time()\n    with ProcessPoolExecutor() as pool:\n\n        result = sum(pool.map(f, L))\n    end = time()\n    \n    print(f\"result = {result} and time = {end-begin}\")","execution_count":null,"outputs":[{"name":"stdout","text":"Writing pmap.py\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00010-3c871477-057b-4cfb-ae86-23eb18de441c","output_cleared":false},"source":"import sys\n!{sys.executable} pmap.py","execution_count":null,"outputs":[{"name":"stdout","text":"result = 140 and time = 2.0561463832855225\r\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- `ProcessPoolExecutor` launches one slave process per physical core on the computer. \n- `pool.map` divides the input list into chunks and puts the tasks (function + chunk) on a queue.\n- Each slave process takes a task (function + a chunk of data), runs map(function, chunk), and puts the result on a result list.\n- `pool.map` on the master process waits until all tasks are handled and returns the concatenation of the result lists.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00011-6fecf1c9-7929-4a3f-9b9f-7b28d5362c51"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00012-f32013a2-fb56-4dee-afb9-67e551946174","output_cleared":false},"source":"%%time\nfrom concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor() as pool:\n\n    results = sum(pool.map(f, L))\n    \nprint(results)","execution_count":null,"outputs":[{"name":"stdout","text":"140\nCPU times: user 6 ms, sys: 7.08 ms, total: 13.1 ms\nWall time: 1.01 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Thread and Process: Differences\n\n- A **process** is an instance of a running program. \n- **Process** may contain one or more **threads**, but a **thread** cannot contain a **process**.\n- **Process** has a self-contained execution environment. It has its own memory space. \n- Application running on your computer may be a set of cooperating **processes**.\n- **Process** don't share its memory, communication between **processes** implies data serialization.\n\n- A **thread** is made of and exist within a **process**; every **process** has at least one **thread**. \n- Multiple **threads** in a **process** share resources, which helps in efficient communication between **threads**.\n- **Threads** can be concurrent on a multi-core system, with every core executing the separate **threads** simultaneously.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00013-87959184-c244-46a3-88b8-a0e692fe1c69"}},{"cell_type":"markdown","source":"## The Global Interpreter Lock (GIL)\n\n- The Python interpreter is not thread safe.\n- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n- The price to pay: serialization of tasks, arguments, and results.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00014-95ae059f-0931-41f9-b605-0b4a4eb851b8"}},{"cell_type":"markdown","source":"## Parallelize text files downloads\n\n- Victor Hugo http://www.gutenberg.org/files/135/135-0.txt\n- Marcel Proust http://www.gutenberg.org/files/7178/7178-8.txt\n- Emile Zola http://www.gutenberg.org/files/1069/1069-0.txt\n- Stendhal http://www.gutenberg.org/files/44747/44747-0.txt\n\n### Exercise 6.1\n\nUse `ThreadPoolExecutor` to parallelize the code above.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00015-64fadb8a-08b6-4990-a4a0-1985c667112f"}},{"cell_type":"code","metadata":{"cell_id":"00016-19ac1c76-86b2-4b97-b359-86a0e4336f93","output_cleared":false},"source":"%mkdir books","execution_count":null,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘books’: File exists\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00017-096986cc-9df8-4d72-b2ee-492eef8f2adb","output_cleared":false},"source":"%%time\nimport urllib.request as url\nsource = \"https://mmassd.github.io/\"  # \"http://svmass2.mass.uhb.fr/hub/static/datasets/\"\nurl.urlretrieve(source+\"books/hugo.txt\",     filename=\"books/hugo.txt\")\nurl.urlretrieve(source+\"books/proust.txt\",   filename=\"books/proust.txt\")\nurl.urlretrieve(source+\"books/zola.txt\",     filename=\"books/zola.txt\")\nurl.urlretrieve(source+\"books/stendhal.txt\", filename=\"books/stendhal.txt\")","execution_count":null,"outputs":[{"name":"stdout","text":"CPU times: user 90 ms, sys: 34 ms, total: 124 ms\nWall time: 1.29 s\n","output_type":"stream"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"('books/stendhal.txt', <http.client.HTTPMessage at 0x7fa7a3b565c0>)"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00018-7375abda-8302-481a-b5b0-024f9b1199a5","output_cleared":false},"source":"%%time\nfrom concurrent.futures import ThreadPoolExecutor\nbooks = [\"hugo.txt\", \"proust.txt\", \"zola.txt\", \"stendhal.txt\"]\nsources = [ source+book for book in books]\nfilenames = [\"books/\"+book for book in books]\n\nwith ThreadPoolExecutor(4) as pool:\n    pool.map(url.urlretrieve, sources, filenames )","execution_count":null,"outputs":[{"name":"stdout","text":"CPU times: user 11.6 ms, sys: 9.83 ms, total: 21.4 ms\nWall time: 108 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Wordcount","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00018-f4da8eea-1eed-4b29-bf6b-92232fd88854"}},{"cell_type":"code","metadata":{"cell_id":"00019-c43ef8bf-64f7-454f-a2c9-357271052a4c","output_cleared":false},"source":"from glob import glob\nfrom collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import chain\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef mapper(filename):\n    \" split text to list of key/value pairs (word,1)\"\n\n    with open(filename) as f:\n        data = f.read()\n        \n    data = data.strip().replace(\".\",\"\").lower().split()\n        \n    return sorted([(w,1) for w in data])\n\ndef partitioner(mapped_values):\n    \"\"\" get lists from mapper and create a dict with\n    (word,[1,1,1])\"\"\"\n    \n    res = defaultdict(list)\n    for w, c in mapped_values:\n        res[w].append(c)\n        \n    return res.items()\n\ndef reducer( item ):\n    \"\"\" Compute words occurences from dict computed\n    by partioner\n    \"\"\"\n    w, v = item\n    return (w,len(v))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parallel map\n\n\n- Let's improve the `mapper` function by print out inside the function the current process name. \n\n*Example*","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00020-2c55a25b-a96c-438b-a9fe-020937d50fe6"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00021-d833e0fc-79f5-4824-99a1-cd9c5555f7bb","output_cleared":false},"source":"import multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef process_name(n):\n    \" prints out the current process name \"\n    print(f\"{mp.current_process().name} \")\n\nwith ProcessPoolExecutor() as e:\n    _ = e.map(process_name, range(mp.cpu_count()))","execution_count":null,"outputs":[{"name":"stdout","text":"ForkProcess-6 \nForkProcess-7 ForkProcess-8 ForkProcess-5 \n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Exercise 6.2\n\n- Modify the mapper function by adding this print.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00022-59f4de93-1fb3-433f-a677-1007c45e1aec"}},{"cell_type":"markdown","source":"## Parallel reduce\n\n- For parallel reduce operation, data must be aligned in a container. We already created a `partitioner` function that returns this container.\n\n### Exercise 6.3\n\nWrite a parallel program that uses the three functions above using `ThreadPoolExecutor`. It reads all the \"sample\\*.txt\" files. Map and reduce steps are parallel.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00023-1aebda59-d029-40fb-a150-06dcb483e6db"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00025-039179c1-2ac1-4046-877b-68dfb60c3c94","output_cleared":false},"source":"from itertools import chain\nfrom operator import itemgetter\nfrom glob import glob\nfrom concurrent.futures import ThreadPoolExecutor\n\nfiles = glob(\"sample0*.txt\")\n\nwith ThreadPoolExecutor() as pool:\n    map_files = pool.map(mapper, files)\n    partitioned_data = pool.map(partitioner, map_files)\n    partitioned_results = pool.map(reducer, chain(*partitioned_data))\n\nresults = defaultdict(int)\n\nfor w in partitioned_results:\n    results[w[0]] += w[1]\nsorted(results.items(), key=itemgetter(1), reverse=True)","execution_count":null,"outputs":[{"name":"stdout","text":"MainProcess sample03.txt\nMainProcess sample06.txt\nMainProcess sample01.txt\nMainProcess sample00.txt\nMainProcess sample07.txt\nMainProcess sample05.txtMainProcess sample02.txt\n\nMainProcess sample04.txt\n","output_type":"stream"},{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"[('dolor', 74),\n ('consectetur', 72),\n ('neque', 71),\n ('ipsum', 69),\n ('quiquia', 69),\n ('labore', 67),\n ('etincidunt', 64),\n ('quaerat', 62),\n ('numquam', 60),\n ('quisquam', 59),\n ('sed', 58),\n ('modi', 57),\n ('ut', 55),\n ('velit', 55),\n ('eius', 54),\n ('aliquam', 53),\n ('dolore', 53),\n ('tempora', 53),\n ('amet', 50),\n ('sit', 49),\n ('adipisci', 48),\n ('est', 45),\n ('magnam', 45),\n ('voluptatem', 45),\n ('porro', 44),\n ('non', 43),\n ('dolorem', 37)]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Increase volume of data\n\n*Due to the proxy, code above is not runnable on workstations*\n\n### Getting the data\n\n- [The Latin Library](http://www.thelatinlibrary.com/) contains a huge collection of freely accessible Latin texts. We get links on the Latin Library's homepage ignoring some links that are not associated with a particular author.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00024-06200911-29cc-4063-8d10-c727062ab306"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00027-e7bc058d-a826-4080-b4ea-b9cd30d9525d","output_cleared":false},"source":"%pip install lxml","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lxml in /opt/venv/lib/python3.7/site-packages (4.5.2)\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00025-4367b6fe-d051-4238-9823-3efb71e12d0a","output_cleared":false},"source":"from bs4 import BeautifulSoup  # web scraping library\nfrom urllib.request import *\n\nbase_url = \"http://www.thelatinlibrary.com/\"\nhome_content = urlopen(base_url)\n\nsoup = BeautifulSoup(home_content, \"lxml\")\nauthor_page_links = soup.find_all(\"a\")\nauthor_pages = [ap[\"href\"] for i, ap in enumerate(author_page_links) if i < 49]","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate html links\n\n- Create a list of all links pointing to Latin texts. The Latin Library uses a special format which makes it easy to find the corresponding links: All of these links contain the name of the text author.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00026-6ea15c82-b5bb-49a1-944f-ce8573767097"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00027-3a19e953-c48a-4ebc-9ca8-a258aa31a7fa","output_cleared":false},"source":"ap_content = list()\nfor ap in author_pages:\n    ap_content.append(urlopen(base_url + ap))\n\nbook_links = list()\nfor path, content in zip(author_pages, ap_content):\n    author_name = path.split(\".\")[0]\n    ap_soup = BeautifulSoup(content, \"lxml\")\n    book_links += ([link for link in ap_soup.find_all(\"a\", {\"href\": True}) if author_name in link[\"href\"]])","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download webpages content","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00028-330d319f-3e3d-4ac9-9cb0-8d3ff958ace5"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00029-e26f5cf7-acbc-4e58-b6ea-13a0664906e2","output_cleared":false},"source":"from urllib.error import HTTPError\n\nnum_pages = 100\n\nfor i, bl in enumerate(book_links[:num_pages]):\n    print(\"Getting content \" + str(i + 1) + \" of \" + str(num_pages), end=\"\\r\", flush=True)\n    try:\n        content = urlopen(base_url + bl[\"href\"]).read()\n        with open(f\"book-{i:03d}.dat\",\"wb\") as f:\n            f.write(content)\n    except HTTPError as err:\n        print(\"Unable to retrieve \" + bl[\"href\"] + \".\")\n        continue","execution_count":null,"outputs":[{"name":"stdout","text":"Getting content 100 of 100\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### Extract data files\n\n- I already put the content of pages in files named book-*.txt\n- You can extract data from the archive by running the cell below","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00030-bd5230b5-b003-4d89-a12f-c6d1ce5cbdc0"}},{"cell_type":"markdown","source":"```py\nimport os  # library to get directory and file paths\nimport tarfile # this module makes possible to read and write tar archives\n\ndef extract_data():\n    datadir = os.path.join('data','latinbooks')\n    if not os.path.exists(datadir):\n       print(\"Extracting data...\")\n       tar_path = os.path.join('data', 'latinbooks.tgz')\n       with tarfile.open(tar_path, mode='r:gz') as books:\n          books.extractall('data')\n            \nextract_data() # this function call will extract text files in data/latinbooks\n```","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00031-35d00e4e-a93c-4b4a-b8c6-c4b1c6735251"}},{"cell_type":"markdown","source":"### Read data files","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00032-d2a0a6f9-5c76-4e39-b689-9579cd495814"}},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00033-ce4fe5c1-3406-4c35-a0a1-c9ef8a6635ce","output_cleared":false},"source":"from glob import glob\nfiles = glob('book*.dat')\ntexts = list()\nfor file in files:\n    with open(file,'rb') as f:\n        text = f.read()\n    texts.append(text)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract the text from html and split the text at periods to convert it into sentences.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00034-a29ffee5-4cbe-43b9-9a4e-a80e115568cc"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00037-bac6178a-2ea7-4d88-ac31-472f569a14ed","output_cleared":false},"source":"%pip install bs4","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting bs4\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\nCollecting beautifulsoup4\n  Downloading beautifulsoup4-4.9.2-py3-none-any.whl (115 kB)\n\u001b[K     |████████████████████████████████| 115 kB 3.5 MB/s eta 0:00:01\n\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\"\n  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\nBuilding wheels for collected packages: bs4\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=f488e46b65fa53acdae92a041ec1dd618de92ffc7bd70b530e004c431c8c72e2\n  Stored in directory: /home/jovyan/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\nSuccessfully built bs4\nInstalling collected packages: soupsieve, beautifulsoup4, bs4\nSuccessfully installed beautifulsoup4-4.9.2 bs4-0.0.1 soupsieve-2.0.1\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"slideshow":{"slide_type":"fragment"},"cell_id":"00035-7b691054-629b-45d7-bca3-8c19e7c5f032","output_cleared":false},"source":"%%time\nfrom bs4 import BeautifulSoup\n\nsentences = list()\n\nfor i, text in enumerate(texts):\n    print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n    textSoup = BeautifulSoup(text, \"lxml\")\n    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n    for t in prepared.split(\".\"):\n        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n        sentences.append(part.strip())\n\n# print first and last sentence to check the results\nprint(sentences[0])\nprint(sentences[-1])","execution_count":null,"outputs":[{"name":"stdout","text":"Document 100 of 100\nviii   quid quod miser cum loqui non posset tacere non poterat\nCPU times: user 12.8 s, sys: 140 ms, total: 12.9 s\nWall time: 12.9 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Exercise 6.4\n\nParallelize this last process using `concurrent.futures`.","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00036-b509b30f-5b5b-4b6f-ba41-907716bedca6"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00041-774d5850-e09b-4373-b2be-6d34249bc73c","output_cleared":false},"source":"%%time\nfrom bs4 import BeautifulSoup\nfrom concurrent.futures import ThreadPoolExecutor\nfrom itertools import chain\n\ndef process_text(text):\n    sentences = list()\n    #print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n    textSoup = BeautifulSoup(text, \"lxml\")\n    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n    for t in prepared.split(\".\"):\n        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n        sentences.append(part.strip())\n    return sentences\n\nindexes = range(len(texts))\n\nwith ThreadPoolExecutor() as pool:\n    mapped_sentences = pool.map(process_text, texts)\n\nsentences = list(chain(*mapped_sentences))   \n# print first and last sentence to check the results\nprint(sentences[0])\nprint(sentences[-1])","execution_count":null,"outputs":[{"name":"stdout","text":"\nviii   quid quod miser cum loqui non posset tacere non poterat\nCPU times: user 15.4 s, sys: 2.13 s, total: 17.5 s\nWall time: 16 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## References\n\n- [Using Conditional Random Fields and Python for Latin word segmentation](https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513)","metadata":{"slideshow":{"slide_type":"slide"},"cell_id":"00037-244fbb8c-dcc3-4707-b2b0-f3d1435b64f8"}}],"nbformat":4,"nbformat_minor":4,"metadata":{"jupytext":{"cell_metadata_json":true},"kernelspec":{"display_name":"big-data","language":"python","name":"big-data"},"deepnote_notebook_id":"790e741a-4d03-4745-8621-05272c2d3eb7","deepnote_execution_queue":[]}}