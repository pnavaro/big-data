{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-7f5358b0-f5e4-4239-b111-a84cac89d008",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Computation\n",
    "\n",
    "This notebook objective is to learn how to parallelize application with Python\n",
    "\n",
    "## Parallel computers\n",
    "- Multiprocessor/multicore: several processors work on data stored in shared memory\n",
    "- Cluster: several processor/memory units work together by exchanging data over a network\n",
    "- Co-processor: a general-purpose processor delegates specific tasks to a special-purpose processor (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-c89520b2-79d7-41b1-bc94-bef944269719",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Programming\n",
    "- Decomposition of the complete task into independent subtasks and the data flow between them.\n",
    "- Distribution of the subtasks over the processors minimizing the total execution time.\n",
    "- For clusters: distribution of the data over the nodes minimizing the communication time.\n",
    "- For multiprocessors: optimization of the memory access patterns minimizing waiting times.\n",
    "- Synchronization of the individual processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-8ed39e2b-06d6-4b45-a07b-93c7426d8866",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-a6d0d1b5-7958-41b2-86cf-215e54f2567e",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "L = list(range(8))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-0368a8cd-8a8e-46e5-86ac-690071ddedd7",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%time sum(f(x) for x in L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-f2152918-0d12-4c04-9c6d-998ff31bda75",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%time sum(map(f,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-90276e80-5472-4382-921f-9f1cd0c80459",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing \n",
    "\n",
    "`multiprocessing` is a package that supports spawning processes.\n",
    "\n",
    "We can use it to display how many concurrent processes you can launch on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-54f6b4f2-bf5a-4f94-9ec6-2d31b317dcfe",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-5e980cdb-7f76-4364-93a0-d4eb3f5a77a0",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with:\n",
    "- **threads**, using ThreadPoolExecutor, \n",
    "- separate **processes**, using ProcessPoolExecutor. \n",
    "Both implement the same interface, which is defined by the abstract Executor class.\n",
    "\n",
    "`concurrent.futures` can't launch **processes** on windows. Windows users must install \n",
    "[loky](https://github.com/tomMoral/loky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-505b529f-4676-497f-8bfb-4c7725e792bf",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%file pmap.py\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from time import sleep, time\n",
    "\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "\n",
    "L = list(range(8))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    begin = time()\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "\n",
    "        result = sum(pool.map(f, L))\n",
    "    end = time()\n",
    "    \n",
    "    print(f\"result = {result} and time = {end-begin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-3c871477-057b-4cfb-ae86-23eb18de441c",
    "deepnote_cell_type": "code",
    "output_cleared": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} pmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-6fecf1c9-7929-4a3f-9b9f-7b28d5362c51",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `ProcessPoolExecutor` launches one slave process per physical core on the computer. \n",
    "- `pool.map` divides the input list into chunks and puts the tasks (function + chunk) on a queue.\n",
    "- Each slave process takes a task (function + a chunk of data), runs map(function, chunk), and puts the result on a result list.\n",
    "- `pool.map` on the master process waits until all tasks are handled and returns the concatenation of the result lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-f32013a2-fb56-4dee-afb9-67e551946174",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as pool:\n",
    "\n",
    "    results = sum(pool.map(f, L))\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-87959184-c244-46a3-88b8-a0e692fe1c69",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thread and Process: Differences\n",
    "\n",
    "- A **process** is an instance of a running program. \n",
    "- **Process** may contain one or more **threads**, but a **thread** cannot contain a **process**.\n",
    "- **Process** has a self-contained execution environment. It has its own memory space. \n",
    "- Application running on your computer may be a set of cooperating **processes**.\n",
    "- **Process** don't share its memory, communication between **processes** implies data serialization.\n",
    "\n",
    "- A **thread** is made of and exist within a **process**; every **process** has at least one **thread**. \n",
    "- Multiple **threads** in a **process** share resources, which helps in efficient communication between **threads**.\n",
    "- **Threads** can be concurrent on a multi-core system, with every core executing the separate **threads** simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-95ae059f-0931-41f9-b605-0b4a4eb851b8",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock (GIL)\n",
    "\n",
    "- The Python interpreter is not thread safe.\n",
    "- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n",
    "- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n",
    "- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n",
    "- The price to pay: serialization of tasks, arguments, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-64fadb8a-08b6-4990-a4a0-1985c667112f",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelize text files downloads\n",
    "\n",
    "- Victor Hugo http://www.gutenberg.org/files/135/135-0.txt\n",
    "- Marcel Proust http://www.gutenberg.org/files/7178/7178-8.txt\n",
    "- Emile Zola http://www.gutenberg.org/files/1069/1069-0.txt\n",
    "- Stendhal http://www.gutenberg.org/files/44747/44747-0.txt\n",
    "\n",
    "### Exercise 6.1\n",
    "\n",
    "Use `ThreadPoolExecutor` to parallelize the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-19ac1c76-86b2-4b97-b359-86a0e4336f93",
    "deepnote_cell_type": "code",
    "output_cleared": false
   },
   "outputs": [],
   "source": [
    "%mkdir books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-096986cc-9df8-4d72-b2ee-492eef8f2adb",
    "deepnote_cell_type": "code",
    "output_cleared": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import urllib.request as url\n",
    "source = \"https://mmassd.github.io/\"  # \"http://svmass2.mass.uhb.fr/hub/static/datasets/\"\n",
    "url.urlretrieve(source+\"books/hugo.txt\",     filename=\"books/hugo.txt\")\n",
    "url.urlretrieve(source+\"books/proust.txt\",   filename=\"books/proust.txt\")\n",
    "url.urlretrieve(source+\"books/zola.txt\",     filename=\"books/zola.txt\")\n",
    "url.urlretrieve(source+\"books/stendhal.txt\", filename=\"books/stendhal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-7375abda-8302-481a-b5b0-024f9b1199a5",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "books = [\"hugo.txt\", \"proust.txt\", \"zola.txt\", \"stendhal.txt\"]\n",
    "sources = [ source+book for book in books]\n",
    "filenames = [\"books/\"+book for book in books]\n",
    "\n",
    "with ThreadPoolExecutor(4) as pool:\n",
    "    pool.map(url.urlretrieve, sources, filenames )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-f4da8eea-1eed-4b29-bf6b-92232fd88854",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-c43ef8bf-64f7-454f-a2c9-357271052a4c",
    "deepnote_cell_type": "code",
    "output_cleared": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def mapper(filename):\n",
    "    \" split text to list of key/value pairs (word,1)\"\n",
    "\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    data = data.strip().replace(\".\",\"\").lower().split()\n",
    "        \n",
    "    return sorted([(w,1) for w in data])\n",
    "\n",
    "def partitioner(mapped_values):\n",
    "    \"\"\" get lists from mapper and create a dict with\n",
    "    (word,[1,1,1])\"\"\"\n",
    "    \n",
    "    res = defaultdict(list)\n",
    "    for w, c in mapped_values:\n",
    "        res[w].append(c)\n",
    "        \n",
    "    return res.items()\n",
    "\n",
    "def reducer( item ):\n",
    "    \"\"\" Compute words occurences from dict computed\n",
    "    by partioner\n",
    "    \"\"\"\n",
    "    w, v = item\n",
    "    return (w,len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-2c55a25b-a96c-438b-a9fe-020937d50fe6",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Parallel map\n",
    "\n",
    "\n",
    "- Let's improve the `mapper` function by print out inside the function the current process name. \n",
    "\n",
    "*Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-d833e0fc-79f5-4824-99a1-cd9c5555f7bb",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def process_name(n):\n",
    "    \" prints out the current process name \"\n",
    "    print(f\"{mp.current_process().name} \")\n",
    "\n",
    "with ProcessPoolExecutor() as e:\n",
    "    _ = e.map(process_name, range(mp.cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-59f4de93-1fb3-433f-a677-1007c45e1aec",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "- Modify the mapper function by adding this print."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-1aebda59-d029-40fb-a150-06dcb483e6db",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel reduce\n",
    "\n",
    "- For parallel reduce operation, data must be aligned in a container. We already created a `partitioner` function that returns this container.\n",
    "\n",
    "### Exercise 6.3\n",
    "\n",
    "Write a parallel program that uses the three functions above using `ThreadPoolExecutor`. It reads all the \"sample\\*.txt\" files. Map and reduce steps are parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00025-039179c1-2ac1-4046-877b-68dfb60c3c94",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "from glob import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "files = glob(\"sample0*.txt\")\n",
    "\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    map_files = pool.map(mapper, files)\n",
    "    partitioned_data = pool.map(partitioner, map_files)\n",
    "    partitioned_results = pool.map(reducer, chain(*partitioned_data))\n",
    "\n",
    "results = defaultdict(int)\n",
    "\n",
    "for w in partitioned_results:\n",
    "    results[w[0]] += w[1]\n",
    "sorted(results.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-06200911-29cc-4063-8d10-c727062ab306",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Increase volume of data\n",
    "\n",
    "*Due to the proxy, code above is not runnable on workstations*\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "- [The Latin Library](http://www.thelatinlibrary.com/) contains a huge collection of freely accessible Latin texts. We get links on the Latin Library's homepage ignoring some links that are not associated with a particular author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-e7bc058d-a826-4080-b4ea-b9cd30d9525d",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00025-4367b6fe-d051-4238-9823-3efb71e12d0a",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # web scraping library\n",
    "from urllib.request import *\n",
    "\n",
    "base_url = \"http://www.thelatinlibrary.com/\"\n",
    "home_content = urlopen(base_url)\n",
    "\n",
    "soup = BeautifulSoup(home_content, \"lxml\")\n",
    "author_page_links = soup.find_all(\"a\")\n",
    "author_pages = [ap[\"href\"] for i, ap in enumerate(author_page_links) if i < 49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-6ea15c82-b5bb-49a1-944f-ce8573767097",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate html links\n",
    "\n",
    "- Create a list of all links pointing to Latin texts. The Latin Library uses a special format which makes it easy to find the corresponding links: All of these links contain the name of the text author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-3a19e953-c48a-4ebc-9ca8-a258aa31a7fa",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ap_content = list()\n",
    "for ap in author_pages:\n",
    "    ap_content.append(urlopen(base_url + ap))\n",
    "\n",
    "book_links = list()\n",
    "for path, content in zip(author_pages, ap_content):\n",
    "    author_name = path.split(\".\")[0]\n",
    "    ap_soup = BeautifulSoup(content, \"lxml\")\n",
    "    book_links += ([link for link in ap_soup.find_all(\"a\", {\"href\": True}) if author_name in link[\"href\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-330d319f-3e3d-4ac9-9cb0-8d3ff958ace5",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Download webpages content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00029-e26f5cf7-acbc-4e58-b6ea-13a0664906e2",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "num_pages = 100\n",
    "\n",
    "for i, bl in enumerate(book_links[:num_pages]):\n",
    "    print(\"Getting content \" + str(i + 1) + \" of \" + str(num_pages), end=\"\\r\", flush=True)\n",
    "    try:\n",
    "        content = urlopen(base_url + bl[\"href\"]).read()\n",
    "        with open(f\"book-{i:03d}.dat\",\"wb\") as f:\n",
    "            f.write(content)\n",
    "    except HTTPError as err:\n",
    "        print(\"Unable to retrieve \" + bl[\"href\"] + \".\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-bd5230b5-b003-4d89-a12f-c6d1ce5cbdc0",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract data files\n",
    "\n",
    "- I already put the content of pages in files named book-*.txt\n",
    "- You can extract data from the archive by running the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-35d00e4e-a93c-4b4a-b8c6-c4b1c6735251",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```py\n",
    "import os  # library to get directory and file paths\n",
    "import tarfile # this module makes possible to read and write tar archives\n",
    "\n",
    "def extract_data():\n",
    "    datadir = os.path.join('data','latinbooks')\n",
    "    if not os.path.exists(datadir):\n",
    "       print(\"Extracting data...\")\n",
    "       tar_path = os.path.join('data', 'latinbooks.tgz')\n",
    "       with tarfile.open(tar_path, mode='r:gz') as books:\n",
    "          books.extractall('data')\n",
    "            \n",
    "extract_data() # this function call will extract text files in data/latinbooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-d2a0a6f9-5c76-4e39-b689-9579cd495814",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-ce4fe5c1-3406-4c35-a0a1-c9ef8a6635ce",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('book*.dat')\n",
    "texts = list()\n",
    "for file in files:\n",
    "    with open(file,'rb') as f:\n",
    "        text = f.read()\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-a29ffee5-4cbe-43b9-9a4e-a80e115568cc",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract the text from html and split the text at periods to convert it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-bac6178a-2ea7-4d88-ac31-472f569a14ed",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-7b691054-629b-45d7-bca3-8c19e7c5f032",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sentences = list()\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "\n",
    "# print first and last sentence to check the results\n",
    "print(sentences[0])\n",
    "print(sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-b509b30f-5b5b-4b6f-ba41-907716bedca6",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.4\n",
    "\n",
    "Parallelize this last process using `concurrent.futures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00041-774d5850-e09b-4373-b2be-6d34249bc73c",
    "deepnote_cell_type": "code",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import chain\n",
    "\n",
    "def process_text(text):\n",
    "    sentences = list()\n",
    "    #print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "    return sentences\n",
    "\n",
    "indexes = range(len(texts))\n",
    "\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    mapped_sentences = pool.map(process_text, texts)\n",
    "\n",
    "sentences = list(chain(*mapped_sentences))   \n",
    "# print first and last sentence to check the results\n",
    "print(sentences[0])\n",
    "print(sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00037-244fbb8c-dcc3-4707-b2b0-f3d1435b64f8",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- [Using Conditional Random Fields and Python for Latin word segmentation](https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "790e741a-4d03-4745-8621-05272c2d3eb7",
  "jupytext": {
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
