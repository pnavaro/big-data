{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8d0a5548941a4559861f9fdb95fa37b3",
    "deepnote_cell_height": 494.59375,
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NYC Flights data 2013 with Weather data\n",
    "\n",
    "Reference : https://github.com/rich-iannone/so-many-pyspark-examples/blob/main/spark-dataframes.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e04e8f8a418840098b98037121ea5da7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1664193365062,
    "output_cleared": false,
    "slideshow": {
     "slide_type": "fragment"
    },
    "source_hash": "88a3037b"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .appName(\"Convert CSV to parquet\") \\\n",
    "        .master(\"spark://b2-120-gra11:7077\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins\n",
    "\n",
    "Joins are easily performed with Spark DataFrames. The expression is:\n",
    "\n",
    "`join(other, on = None, how = None)`\n",
    "\n",
    "where:\n",
    "- other: a DataFrame that serves as the right side of the join\n",
    "- on: typically a join expression\n",
    "- how: the default is `inner` but there are also `inner`, `outer`, `left_outer`, `right_outer`, and `leftsemi` joins available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in some more data so that we can have two DataFrames to join. The **CSV** file `weather.csv` contains hourly meteorological data from EWR during 2013. `nycflights2013.csv` contains flights data duringthe same period.\n",
    "Lets create nycflights2013 using a schema object made with `pyspark.sql.type``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *  # Necessary for creating schemas\n",
    "from pyspark.sql.functions import * # Importing PySpark functions\n",
    "\n",
    "nycflights_schema = StructType([\n",
    "  StructField('year', IntegerType(), True),\n",
    "  StructField('month', IntegerType(), True),\n",
    "  StructField('day', IntegerType(), True),\n",
    "  StructField('dep_time', StringType(), True),\n",
    "  StructField('dep_delay', IntegerType(), True),\n",
    "  StructField('arr_time', StringType(), True),\n",
    "  StructField('arr_delay', IntegerType(), True),\n",
    "  StructField('carrier', StringType(), True),\n",
    "  StructField('tailnum', StringType(), True),\n",
    "  StructField('flight', StringType(), True),  \n",
    "  StructField('origin', StringType(), True),\n",
    "  StructField('dest', StringType(), True),\n",
    "  StructField('air_time', IntegerType(), True),\n",
    "  StructField('distance', IntegerType(), True),\n",
    "  StructField('hour', IntegerType(), True),\n",
    "  StructField('minute', IntegerType(), True)\n",
    "  ])\n",
    "\n",
    "# ...and then read the CSV with the schema\n",
    "nycflights13_csv = spark.read.csv(\"file:///srv/data/nycflights/nycflights13.csv\", schema = nycflights_schema )\n",
    "nycflights13_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a proper timestamp.\n",
    "\n",
    "We have all the components: `year`, `month`, `day`, `hour`, and `minute`.\n",
    "\n",
    "Use `concat_ws()` (concatentate with separator) to combine column data into StringType columns such that dates (`-` separator, YYYY-MM-DD) and times (`:` separator, 24-hour time) are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights13 = \\\n",
    "(nycflights13_csv\n",
    " .withColumn('date',\n",
    "             concat_ws('-',\n",
    "                       nycflights13_csv.year,\n",
    "                       nycflights13_csv.month,\n",
    "                       nycflights13_csv.day))\n",
    " .withColumn('time',\n",
    "             concat_ws(':',\n",
    "                       nycflights13_csv.hour,\n",
    "                       nycflights13_csv.minute)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a second step, concatenate with `concat_ws()` the `date` and `time` strings (separator is a space); then drop several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights13 = \\\n",
    "(nycflights13\n",
    " .withColumn('timestamp',\n",
    "             concat_ws(' ',\n",
    "                       nycflights13.date,\n",
    "                       nycflights13.time))\n",
    " .drop('date')     # `drop()` doesn't accept a list of column names, therefore, for every column, \n",
    " .drop('minute')   # we would like to remove from the DataFrame, we must create a new `drop()`\n",
    " .drop('time'))    # statement\n",
    "\n",
    "# In the final step, convert the `timestamp` from\n",
    "# a StringType into a TimestampType\n",
    "nycflights13 = \\\n",
    "(nycflights13\n",
    " .withColumn('timestamp',\n",
    "             to_utc_timestamp(nycflights13.timestamp, 'GMT')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a schema object and then read the CSV with the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_schema = StructType([  \n",
    "  StructField('year', IntegerType(), True),\n",
    "  StructField('month', IntegerType(), True),\n",
    "  StructField('day', IntegerType(), True),\n",
    "  StructField('hour', IntegerType(), True),\n",
    "  StructField('temp', FloatType(), True),\n",
    "  StructField('dewp', FloatType(), True),\n",
    "  StructField('humid', FloatType(), True),\n",
    "  StructField('wind_dir', IntegerType(), True),\n",
    "  StructField('wind_speed', FloatType(), True),\n",
    "  StructField('wind_gust', FloatType(), True),\n",
    "  StructField('precip', FloatType(), True),\n",
    "  StructField('pressure', FloatType(), True),\n",
    "  StructField('visib', FloatType(), True)\n",
    "  ])\n",
    "\n",
    "\n",
    "weather = spark.read.csv(\"file:///srv/data/nycflights/weather.csv\", schema = weather_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the `nycflights` DF with the `weather` DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_all_columns = \\\n",
    "(nycflights13\n",
    " .join(weather,\n",
    "       [nycflights13.month == weather.month, # three join conditions: month,\n",
    "        nycflights13.day == weather.day,     #                        day,\n",
    "        nycflights13.hour == weather.hour],  #                        hour\n",
    "       'left_outer')) # left outer join: keep all rows from the left DF (flights), with the matching rows in the right DF (weather)\n",
    "                      # NULLs created if there is no match to the right DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_all_columns.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to reduce the number of extraneous columns is to use a `select()` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib = \\\n",
    "(nycflights_all_columns\n",
    " .select(['timestamp', 'carrier', 'flight',\n",
    "          'origin', 'dest', 'wind_dir',\n",
    "          'wind_speed', 'wind_gust', 'visib']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib.schema.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in even more data so we can determine if any takeoffs occurred in very windy weather.\n",
    "\n",
    "The **CSV** `beaufort_land.csv` contains Beaufort scale values (the `force` column), wind speed ranges in *mph*, and the name for each wind force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schema object... \n",
    "beaufort_land_schema = StructType([  \n",
    "  StructField('force', IntegerType(), True),\n",
    "  StructField('speed_mi_h_lb', IntegerType(), True),\n",
    "  StructField('speed_mi_h_ub', IntegerType(), True),\n",
    "  StructField('name', StringType(), True)\n",
    "  ])\n",
    "\n",
    "# ...and then read the CSV with the schema\n",
    "beaufort_land = spark.read.csv('/srv/data/nycflights/beaufort_land.csv', \n",
    "                               header = True, schema = beaufort_land_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beaufort_land.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the current working DF with the `beaufort_land` DF and use join expressions that use the WS ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib_beaufort = \\\n",
    "(nycflights_wind_visib\n",
    " .join(beaufort_land,\n",
    "      [nycflights_wind_visib.wind_speed >= beaufort_land.speed_mi_h_lb,\n",
    "       nycflights_wind_visib.wind_speed < beaufort_land.speed_mi_h_ub],\n",
    "       'left_outer')\n",
    " .withColumn('month', month(nycflights_wind_visib.timestamp)) # Create a month column from `timestamp` values\n",
    " .drop('speed_mi_h_lb')\n",
    " .drop('speed_mi_h_ub')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib_beaufort.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib_beaufort.filter(\"name IS NOT NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_wind_visib_beaufort.filter(\"NOT name IS NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the number of potentially dangerous\n",
    "takeoffs (i.e., where the Beaufort force is high)\n",
    "month-by-month through the use of the `crosstab()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_month_force = \\\n",
    "(nycflights_wind_visib_beaufort\n",
    " .crosstab('month', 'force'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_month_force.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the crosstab DataFrame, use a few functions to clean up the resultant DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_month_force = \\\n",
    "(crosstab_month_force\n",
    " .withColumn('month_force',\n",
    "             crosstab_month_force.month_force.cast('int')) # the column is initially a string but recasting as\n",
    "                                                           # an `int` will aid ordering in the next expression\n",
    " .orderBy('month_force')\n",
    " .drop('null'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_month_force.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions (UDFs)\n",
    "\n",
    "**UDF**s allow for computations of values while looking at every input row in the DataFrame. They allow you to make your own function and import functionality from other **Python** libraries.\n",
    "\n",
    "Define a function to convert velocity from\n",
    "miles per hour (mph) to meters per second (mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mph_to_mps(mph):\n",
    "    try:\n",
    "        mps = mph * 0.44704\n",
    "    except:\n",
    "        mps = 0.0\n",
    "    return mps\n",
    "\n",
    "# Register this function as a UDF using `udf()`\n",
    "mph_to_mps = udf(mph_to_mps, FloatType()) # An output type was specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new columns that are conversions of wind speeds from mph to mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  nycflights_wind_visib_beaufort\n",
    "  .withColumn('wind_speed_mps', mph_to_mps('wind_speed'))\n",
    "  .withColumn('wind_gust_mps', mph_to_mps('wind_gust'))\n",
    "  .withColumnRenamed('wind_speed', 'wind_speed_mph')\n",
    "  .withColumnRenamed('wind_gust', 'wind_gust_mph')\n",
    "  .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "aea00890933e4d91be101c2c40bd0c29",
  "jupytext": {
   "cell_metadata_json": true,
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
