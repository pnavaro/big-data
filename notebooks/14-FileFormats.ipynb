{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-d7da12dc-75b8-418b-a299-239e69c86a15",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# File Formats\n",
    "\n",
    "I present three data formats, feather, parquet and hdf but it exists several more like [Apache Avro](http://avro.apache.org/docs/current/) or [Apache ORC](https://orc.apache.org). \n",
    "\n",
    "These data formats may be more appropriate in certain situations. \n",
    "However, the software needed to handle them is either more difficult \n",
    "to install, incomplete, or more difficult to use because less \n",
    "documentation is provided. For ORC and AVRO the python libraries \n",
    "offered are less well maintained than the formats we will see. You can find many on \n",
    "the web but it is hard to know which one is the most stable. \n",
    "- [pyorc](https://github.com/noirello/pyorc)\n",
    "- [avro](https://avro.apache.org/docs/1.10.0/gettingstartedpython.html) and [fastavro](https://github.com/fastavro/fastavro)\n",
    "The following formats are supported\n",
    "by pandas and apache arrow. These softwares are supported by very strong communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-f391c3d6-f2be-40ff-935a-7dbe66500534",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Feather\n",
    "\n",
    "For light data, it is recommanded to use [Feather](https://github.com/wesm/feather). It is a fast, interoperable data frame storage that comes with bindings for python and R.\n",
    "\n",
    "Feather uses also the Apache Arrow columnar memory specification to represent binary data on disk. This makes read and write operations very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-668ae76d-ef35-44ea-9e89-ed68896e97a1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Parquet file format\n",
    "\n",
    "[Parquet format](https://github.com/apache/parquet-format) is a common binary data store, used particularly in the Hadoop/big-data sphere. It provides several advantages relevant to big-data processing:\n",
    "\n",
    "The Apache Parquet project provides a standardized open-source columnar storage format for use in data analysis systems. It was created originally for use in Apache Hadoop with systems like Apache Drill, Apache Hive, Apache Impala, and Apache Spark adopting it as a shared standard for high performance data IO.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-20ddaff2-d1b2-4377-bba4-8dbe36cb4b0e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Hierarchical Data Format\n",
    "\n",
    " [HDF](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) is a self-describing data format\n",
    "allowing an application to interpret the structure and \n",
    "contents of a file with no outside information. \n",
    "One HDF file can hold a mix of related objects \n",
    "which can be accessed as a group or as individual objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-f27ca6ee-3572-4f04-9682-a21cb054c956",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Let's create some big dataframe with consitent data (Floats) and 10% of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-86f06cb5-60f9-4b76-8b28-d8be6216d31c",
    "deepnote_cell_type": "code",
    "execution_millis": 365,
    "execution_start": 1605607212760,
    "output_cleared": false,
    "source_hash": "2148f3e9"
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "arr = np.random.randn(500000) # 10% nulls\n",
    "arr[::10] = np.nan\n",
    "df = pd.DataFrame({'column_{0}'.format(i): arr for i in range(10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-6c3102ae-966b-4c76-863d-02e663356c24",
    "deepnote_cell_type": "code",
    "execution_millis": 9969,
    "execution_start": 1605607226298,
    "output_cleared": false,
    "source_hash": "601b1750",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.25 s, sys: 467 ms, total: 7.72 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%time df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-eebd2468-f5fd-4c69-83c1-1c7680da818a",
    "deepnote_cell_type": "code",
    "execution_millis": 904,
    "execution_start": 1605607570330,
    "output_cleared": false,
    "source_hash": "648965ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: test.h5: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%rm test.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-3efe272e-e2c6-4f92-a559-d1a7e7cc422e",
    "deepnote_cell_type": "code",
    "execution_millis": 3074,
    "execution_start": 1605607572677,
    "output_cleared": false,
    "source_hash": "9511287b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.6 ms, sys: 70.2 ms, total: 137 ms\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%time df.to_hdf(\"test.h5\", key=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00003-e32d9d18-f251-4149-a739-083b7e98905c",
    "deepnote_cell_type": "code",
    "execution_millis": 1258,
    "execution_start": 1605607364857,
    "output_cleared": false,
    "source_hash": "3658418d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 260 ms, sys: 42.7 ms, total: 303 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%time df.to_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00003-3d58cd78-c520-45a8-aee0-c9786b4ee486",
    "deepnote_cell_type": "code",
    "execution_millis": 524,
    "execution_start": 1605607390362,
    "output_cleared": false,
    "source_hash": "8a260d4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 28 ms, total: 186 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%time df.to_feather('test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00011-ea9189a2-035b-4a8e-84cc-1c71a317ef88",
    "deepnote_cell_type": "code",
    "execution_millis": 51,
    "execution_start": 1605607453945,
    "output_cleared": false,
    "source_hash": "48eefa13",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97M\ttest.csv\n",
      " 36M\ttest.feather\n",
      " 42M\ttest.h5\n",
      " 37M\ttest.parquet\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "du -sh test.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00008-48514262-1c39-4f50-8244-d1e3f75760d8",
    "deepnote_cell_type": "code",
    "execution_millis": 2122,
    "execution_start": 1605607494359,
    "output_cleared": false,
    "source_hash": "5e7e15ac",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 749 ms, sys: 98.7 ms, total: 848 ms\n",
      "Wall time: 850 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00009-fb4d1486-9047-47fd-804b-d8498e9234ce",
    "deepnote_cell_type": "code",
    "execution_millis": 1400,
    "execution_start": 1605607580459,
    "output_cleared": false,
    "source_hash": "71468c8a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 ms, sys: 52.5 ms, total: 103 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_hdf(\"test.h5\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00010-34278fa4-4bee-4496-a023-b02519d5e310",
    "deepnote_cell_type": "code",
    "execution_millis": 871,
    "execution_start": 1605607590036,
    "output_cleared": false,
    "source_hash": "afb15a98",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82.2 ms, sys: 76.4 ms, total: 159 ms\n",
      "Wall time: 623 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00003-304f31cd-09e7-4629-8bcd-29d0d3de97a8",
    "deepnote_cell_type": "code",
    "execution_millis": 504,
    "execution_start": 1605607599396,
    "output_cleared": false,
    "source_hash": "5110928f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 ms, sys: 34.4 ms, total: 66.3 ms\n",
      "Wall time: 30.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_feather(\"test.feather\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00012-200d2d6f-7b4f-4739-87e5-ee1d535d3eea",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1605607647672,
    "output_cleared": false,
    "source_hash": "83688577",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we create a new big dataframe with a column of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00004-9d559345-404e-4d73-bbe0-ab773d5e751b",
    "deepnote_cell_type": "code",
    "execution_millis": 29715,
    "execution_start": 1605607754053,
    "output_cleared": false,
    "source_hash": "11d4259f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lorem import sentence\n",
    "\n",
    "words = np.array(sentence().strip().lower().replace(\".\", \" \").split())\n",
    "\n",
    "# Set the seed so that the numbers can be reproduced.\n",
    "np.random.seed(0)  \n",
    "n = 1000000\n",
    "df = pd.DataFrame(np.c_[np.random.randn(n, 5),\n",
    "                  np.random.randint(0,10,(n, 2)),\n",
    "                  np.random.randint(0,1,(n, 2)),\n",
    "np.array([np.random.choice(words) for i in range(n)])] , \n",
    "columns=list('ABCDEFGHIJ'))\n",
    "\n",
    "df[\"A\"][::10] = np.nan\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00006-dbb81bcb-1dae-4e78-b88f-7261409341b8",
    "deepnote_cell_type": "code",
    "execution_millis": 6742,
    "execution_start": 1605607804335,
    "output_cleared": false,
    "source_hash": "86969307",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 207 ms, total: 4.87 s\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00015-4af8fb60-2e45-41a8-8173-c03959c65112",
    "deepnote_cell_type": "code",
    "execution_millis": 10808,
    "execution_start": 1605607849621,
    "output_cleared": false,
    "source_hash": "60cee7f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed eval>:1: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], dtype='object')]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 539 ms, total: 3.25 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_hdf('test.h5', key=\"test\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00007-169983f0-f35d-4d2d-a62d-dac421509f03",
    "deepnote_cell_type": "code",
    "execution_millis": 2654,
    "execution_start": 1605607878875,
    "output_cleared": false,
    "source_hash": "a5d7fbf1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 768 ms, sys: 136 ms, total: 904 ms\n",
      "Wall time: 836 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_feather('test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00017-a8112e1b-2c08-47ac-b740-059f6cb840b2",
    "deepnote_cell_type": "code",
    "execution_millis": 2305,
    "execution_start": 1605607913541,
    "output_cleared": false,
    "source_hash": "ad143313",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 68.6 ms, total: 1.14 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00018-2b95458f-c287-4419-86e5-c617a63ef1ef",
    "deepnote_cell_type": "code",
    "execution_millis": 8728,
    "execution_start": 1605607923868,
    "output_cleared": false,
    "source_hash": "bdf7d1af",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 216 ms, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_csv(\"test.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00019-ee4b525b-cc49-49a1-85c0-c79bbb36d662",
    "deepnote_cell_type": "code",
    "execution_millis": 13601,
    "execution_start": 1605607936800,
    "output_cleared": false,
    "source_hash": "771dceb3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 420 ms, total: 1.54 s\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_hdf(\"test.h5\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00020-7e533430-03e7-4486-9512-4a5e3fdc7fca",
    "deepnote_cell_type": "code",
    "execution_millis": 9103,
    "execution_start": 1605607954950,
    "output_cleared": false,
    "source_hash": "a1e5a992",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 440 ms, total: 2.06 s\n",
      "Wall time: 1.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_feather('test.feather')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00005-c284124d-89af-4ee1-9c47-60d6d5a0241c",
    "deepnote_cell_type": "code",
    "execution_millis": 10083,
    "execution_start": 1605607999155,
    "output_cleared": false,
    "source_hash": "f37bbfe5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 s, sys: 447 ms, total: 2.24 s\n",
      "Wall time: 1.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_parquet('test.parquet')\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00027-c22ed092-a58d-4375-affd-da5887c25b6d",
    "deepnote_cell_type": "code",
    "execution_millis": 5,
    "execution_start": 1605608063341,
    "output_cleared": false,
    "source_hash": "f30f989a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.4001572083672233</td>\n",
       "      <td>0.9787379841057392</td>\n",
       "      <td>2.240893199201458</td>\n",
       "      <td>1.8675579901499675</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dolorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977277879876411</td>\n",
       "      <td>0.9500884175255894</td>\n",
       "      <td>-0.1513572082976979</td>\n",
       "      <td>-0.10321885179355784</td>\n",
       "      <td>0.41059850193837233</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dolorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144043571160878</td>\n",
       "      <td>1.454273506962975</td>\n",
       "      <td>0.7610377251469934</td>\n",
       "      <td>0.12167501649282841</td>\n",
       "      <td>0.44386323274542566</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33367432737426683</td>\n",
       "      <td>1.4940790731576061</td>\n",
       "      <td>-0.20515826376580087</td>\n",
       "      <td>0.31306770165090136</td>\n",
       "      <td>-0.8540957393017248</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>numquam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.5529898158340787</td>\n",
       "      <td>0.6536185954403606</td>\n",
       "      <td>0.8644361988595057</td>\n",
       "      <td>-0.7421650204064419</td>\n",
       "      <td>2.2697546239876076</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.4543656745987648</td>\n",
       "      <td>0.04575851730144607</td>\n",
       "      <td>-0.1871838500258336</td>\n",
       "      <td>1.5327792143584575</td>\n",
       "      <td>1.469358769900285</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>labore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1549474256969163</td>\n",
       "      <td>0.37816251960217356</td>\n",
       "      <td>-0.8877857476301128</td>\n",
       "      <td>-1.980796468223927</td>\n",
       "      <td>-0.3479121493261526</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>voluptatem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.15634896910398005</td>\n",
       "      <td>1.2302906807277207</td>\n",
       "      <td>1.2023798487844113</td>\n",
       "      <td>-0.3873268174079523</td>\n",
       "      <td>-0.30230275057533557</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0485529650670926</td>\n",
       "      <td>-1.4200179371789752</td>\n",
       "      <td>-1.7062701906250126</td>\n",
       "      <td>1.9507753952317897</td>\n",
       "      <td>-0.5096521817516535</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.4380743016111864</td>\n",
       "      <td>-1.2527953600499262</td>\n",
       "      <td>0.7774903558319101</td>\n",
       "      <td>-1.6138978475579515</td>\n",
       "      <td>-0.2127402802139687</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>voluptatem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A                    B                     C  \\\n",
       "0                 None   0.4001572083672233    0.9787379841057392   \n",
       "1   -0.977277879876411   0.9500884175255894   -0.1513572082976979   \n",
       "2    0.144043571160878    1.454273506962975    0.7610377251469934   \n",
       "3  0.33367432737426683   1.4940790731576061  -0.20515826376580087   \n",
       "4  -2.5529898158340787   0.6536185954403606    0.8644361988595057   \n",
       "5  -1.4543656745987648  0.04575851730144607   -0.1871838500258336   \n",
       "6   0.1549474256969163  0.37816251960217356   -0.8877857476301128   \n",
       "7  0.15634896910398005   1.2302906807277207    1.2023798487844113   \n",
       "8  -1.0485529650670926  -1.4200179371789752   -1.7062701906250126   \n",
       "9  -0.4380743016111864  -1.2527953600499262    0.7774903558319101   \n",
       "\n",
       "                      D                     E  F  G  H  I           J  \n",
       "0     2.240893199201458    1.8675579901499675  0  4  0  0     dolorem  \n",
       "1  -0.10321885179355784   0.41059850193837233  5  5  0  0     dolorem  \n",
       "2   0.12167501649282841   0.44386323274542566  6  1  0  0        eius  \n",
       "3   0.31306770165090136   -0.8540957393017248  0  5  0  0     numquam  \n",
       "4   -0.7421650204064419    2.2697546239876076  6  7  0  0         sed  \n",
       "5    1.5327792143584575     1.469358769900285  6  0  0  0      labore  \n",
       "6    -1.980796468223927   -0.3479121493261526  8  0  0  0  voluptatem  \n",
       "7   -0.3873268174079523  -0.30230275057533557  5  5  0  0         sed  \n",
       "8    1.9507753952317897   -0.5096521817516535  7  5  0  0        eius  \n",
       "9   -1.6138978475579515   -0.2127402802139687  2  0  0  0  voluptatem  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "00011-8618020c-4639-4a88-b9f2-0e1212e9c7cf",
    "deepnote_cell_type": "code",
    "execution_millis": 470,
    "execution_start": 1605608091018,
    "output_cleared": false,
    "source_hash": "d56ddf52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['J'] = pd.Categorical(df.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00023-cf2defbc-03c8-4b43-becd-82bc3e39cdee",
    "deepnote_cell_type": "code",
    "execution_millis": 1959,
    "execution_start": 1605608105636,
    "output_cleared": false,
    "source_hash": "1ddaec9a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 557 ms, sys: 85.9 ms, total: 643 ms\n",
      "Wall time: 597 ms\n"
     ]
    }
   ],
   "source": [
    "%time df.to_feather('test.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00024-8c3f3bc6-d8b5-4915-a22e-89d77df8f8a3",
    "deepnote_cell_type": "code",
    "execution_millis": 2699,
    "execution_start": 1605608134600,
    "output_cleared": false,
    "source_hash": "3658418d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 935 ms, sys: 66.1 ms, total: 1 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%time df.to_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00012-7c986385-4bc6-4c82-8079-36a53df467ef",
    "deepnote_cell_type": "code",
    "execution_millis": 6995,
    "execution_start": 1605608145002,
    "output_cleared": false,
    "source_hash": "a1e5a992",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 s, sys: 322 ms, total: 1.61 s\n",
      "Wall time: 1.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_feather('test.feather')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "00024-245a1c05-2399-4d6c-95f0-195be6f23e3e",
    "deepnote_cell_type": "code",
    "execution_millis": 10342,
    "execution_start": 1605608190354,
    "output_cleared": false,
    "source_hash": "f37bbfe5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 357 ms, total: 1.94 s\n",
      "Wall time: 1.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "df = pd.read_parquet('test.parquet')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-832b0847-4adb-4f4b-8357-66febb207dda",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Feather or Parquet\n",
    "\n",
    "- Parquet format is designed for long-term storage, where Arrow is more intended for short term or ephemeral storage because files volume are larger.\n",
    "- Parquet is usually more expensive to write than Feather as it features more layers of encoding and compression. \n",
    "- Feather is unmodified raw columnar Arrow memory. We will probably add simple compression to Feather in the future.\n",
    "- Due to dictionary encoding, RLE encoding, and data page compression, Parquet files will often be much smaller than Feather files\n",
    "- Parquet is a standard storage format for analytics that's supported by Spark. So if you are doing analytics, Parquet is a good option as a reference storage format for query by multiple systems\n",
    "\n",
    "[source stackoverflow](https://stackoverflow.com/questions/48083405/what-are-the-differences-between-feather-and-parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-9a75a293-b946-4598-bd67-3fd8415c48c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Apache Arrow\n",
    "\n",
    "[Arrow](https://arrow.apache.org/docs/python/) is a columnar in-memory analytics layer designed to accelerate big data. \n",
    "It houses a set of canonical in-memory representations of \n",
    "hierarchical data along with multiple language-bindings \n",
    "for structure manipulation. Arrow offers an unified way to be able to \n",
    "share the same data representation among languages and it will certainly be \n",
    "the next standard to store dataframes in all languages.\n",
    "\n",
    "- [R package](https://cran.r-project.org/web/packages/arrow/index.html)\n",
    "- [Julia package](https://github.com/JuliaData/Arrow.jl)\n",
    "- [GitHub project](https://github.com/apache/arrow)\n",
    "\n",
    "![](images/arrow_ecosystem.png)\n",
    "\n",
    "Apache Arrow is an ideal in-memory transport layer for data that is being read or written with Parquet files. [PyArrow](https://arrow.apache.org/docs/python/) includes Python bindings to read and write Parquet files with pandas.\n",
    "\n",
    "- columnar storage, only read the data of interest\n",
    "- efficient binary packing\n",
    "- choice of compression algorithms and encoding\n",
    "- split data into files, allowing for parallel processing\n",
    "- range of logical types\n",
    "- statistics stored in metadata allow for skipping unneeded chunks\n",
    "- data partitioning using the directory structure\n",
    "\n",
    "![arrow](images/arrow.png)\n",
    "\n",
    "- https://arrow.apache.org/docs/python/csv.html\n",
    "- https://arrow.apache.org/docs/python/feather.html\n",
    "- https://arrow.apache.org/docs/python/parquet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-9a75a293-b946-4598-bd67-3fd8415c48c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Example:\n",
    "\n",
    "```py\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "arr = np.random.randn(500000) # 10% nulls\n",
    "arr[::10] = np.nan\n",
    "df = pd.DataFrame({'column_{0}'.format(i): arr for i in range(10)})\n",
    "\n",
    "hdfs = pa.hdfs.connect()\n",
    "table = pa.Table.from_pandas(df)\n",
    "pq.write_to_dataset(table, root_path=\"test\", filesystem=hdfs)\n",
    "hdfs.ls(\"test\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-9a75a293-b946-4598-bd67-3fd8415c48c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Read CSV from HDFS\n",
    "\n",
    "Put the file test.csv on hdfs system \n",
    "\n",
    "```python\n",
    "from pyarrow import csv\n",
    "with hdfs.open(\"/data/nycflights/1999.csv\", \"rb\") as f:\n",
    " df = pd.read_csv(f, nrows = 10)\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "### Read Parquet File from HDFS with pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "wikipedia = pd.read_parquet(\"hdfs://svmass2.mass.uhb.fr:54310/data/pagecounts-parquet/part-00007-8575060f-6b57-45ea-bf1d-cd77b6141f70.snappy.parquet\", engine=’pyarrow’)\n",
    "print(wikipedia.head())\n",
    "```\n",
    "### Read Parquet File with pyarrow\n",
    "\n",
    "```py\n",
    "table = pq.read_table(\"example.parquet\")\n",
    "```\n",
    "\n",
    "### Writing a parquet file from Apache Arrow\n",
    "```py\n",
    "pq.write_table(table, \"example.parquet\")\n",
    "```\n",
    "\n",
    "### Check metadata\n",
    "```py\n",
    "parquet_file = pq.ParquetFile(\"example.parquet\")\n",
    "print(parquet_file.metadata)\n",
    "```\n",
    "\n",
    "### See schema\n",
    "```py\n",
    "print(parquet_file.schema)\n",
    "```\n",
    "\n",
    "### Connect to the Hadoop file system\n",
    "\n",
    "```py\n",
    "hdfs = pa.hdfs.connect()\n",
    "\n",
    "# copy to local\n",
    "with hdfs.open(\"user.txt\", \"rb\") as f:\n",
    "    f.download(\"user.text\")\n",
    "\n",
    "# write parquet file on hdfs\n",
    "with open(\"example.parquet\", \"rb\") as f:\n",
    "    pa.HadoopFileSystem.upload(hdfs, \"example.parquet\", f)\n",
    "\n",
    "# List files\n",
    "for f in hdfs.ls(\"/user/navaro_p\"):\n",
    "    print(f)\n",
    "\n",
    "# create a small dataframe and write it to hadoop file system\n",
    "small_df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n",
    "table = pa.Table.from_pandas(small_df)\n",
    "pq.write_table(table, \"small_df.parquet\", filesystem=hdfs)\n",
    "\n",
    "\n",
    "# Read files from Hadoop with pandas\n",
    "with hdfs.open(\"/data/irmar.csv\") as f:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Read parquet file from Hadoop with pandas\n",
    "server = \"hdfs://svmass2.mass.uhb.fr:54310\"\n",
    "path = \"data/pagecounts-parquet/part-00007-8575060f-6b57-45ea-bf1d-cd77b6141f70.snappy.parquet\"\n",
    "pagecount = pd.read_parquet(os.path.join(server, path), engine=\"pyarrow\")\n",
    "print(pagecount.head())\n",
    "\n",
    "# Read parquet file from Hadoop with pyarrow\n",
    "table = pq.read_table(os.path.join(server,path))\n",
    "print(table.schema)\n",
    "df = table.to_pandas()\n",
    "print(df.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-c0409d84-12d4-42c5-adb2-ce319b58d5be",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Take the second dataframe with string as last column\n",
    "- Create an arrow table from pandas dataframe\n",
    "- Write the file test.parquet from arrow table\n",
    "- Print metadata from this parquet file\n",
    "- Print schema\n",
    "- Upload the file to hadoop file system\n",
    "- Read this file from hadoop file system and print dataframe head\n",
    "\n",
    "\n",
    "Hint: check the doc https://arrow.apache.org/docs/python/parquet.html"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "a7088f08-45cf-4fa4-910d-a13ff12600d1",
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
