
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Hadoop &#8212; Python tools for Big data</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://pnavaro.github.io/big-data/13-Hadoop.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="File Formats" href="14-FileFormats.html" />
    <link rel="prev" title="Basic Commands in the Unix Shell" href="12-UnixCommands.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logoR2-Noir.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python tools for Big data</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-GitBasics.html">
   Git basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-Installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-JupyterQuickStart.html">
   Jupyter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-WordCount.html">
   Wordcount
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05-MapReduce.html">
   Map Reduce
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-ParallelComputation.html">
   Parallel Computation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07-AsynchronousProcessing.html">
   Asynchronous Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-DaskDelayed.html">
   Dask
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-DaskBag.html">
   Dask bag
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10-PandasSeries.html">
   Pandas Series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11-PandaDataframes.html">
   Pandas Dataframes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12-UnixCommands.html">
   Basic Commands in the Unix Shell
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Hadoop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-FileFormats.html">
   File Formats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15-PySpark.html">
   PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16-DaskDataframes.html">
   Dask Dataframes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-SparkDataFrames.html">
   Spark DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18-NYCTaxiCabTripDask.html">
   Dask dataframes on HDFS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19-NYCTaxiCabTripSpark.html">
   Spark dataframes on HDFS
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/13-Hadoop.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/pnavaro/big-data"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/pnavaro/big-data/issues/new?title=Issue%20on%20page%20%2F13-Hadoop.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/pnavaro/big-data/edit/master/notebooks/13-Hadoop.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/pnavaro/big-data/master?urlpath=tree/notebooks/13-Hadoop.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/pnavaro/big-data/blob/master/notebooks/13-Hadoop.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hdfs">
   HDFS
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#accessibility">
   Accessibility
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#manage-files-and-directories">
   Manage files and directories
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-between-nodes">
   Transfer between nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#put">
     put
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hadoop-cluster">
   Hadoop cluster
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#namenode-web-interface-hdfs-layer">
     NameNode Web Interface (HDFS layer)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#secondary-namenode-information">
     Secondary Namenode Information.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datanode-information">
     Datanode Information.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hands-on-practice">
   Hands-on practice:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#yarn">
   YARN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#yarn-web-interface">
     Yarn Web Interface
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wordcount-example">
   WordCount Example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deploying-the-mapreduce-python-code-on-hadoop">
   Deploying the MapReduce Python code on Hadoop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#map">
   Map
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reduce">
   Reduce
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#execution-on-hadoop-cluster">
   Execution on Hadoop cluster
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Hadoop</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hdfs">
   HDFS
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#accessibility">
   Accessibility
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#manage-files-and-directories">
   Manage files and directories
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-between-nodes">
   Transfer between nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#put">
     put
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hadoop-cluster">
   Hadoop cluster
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#namenode-web-interface-hdfs-layer">
     NameNode Web Interface (HDFS layer)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#secondary-namenode-information">
     Secondary Namenode Information.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datanode-information">
     Datanode Information.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hands-on-practice">
   Hands-on practice:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#yarn">
   YARN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#yarn-web-interface">
     Yarn Web Interface
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wordcount-example">
   WordCount Example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deploying-the-mapreduce-python-code-on-hadoop">
   Deploying the MapReduce Python code on Hadoop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#map">
   Map
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reduce">
   Reduce
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#execution-on-hadoop-cluster">
   Execution on Hadoop cluster
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="hadoop">
<h1>Hadoop<a class="headerlink" href="#hadoop" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Data sets that are so large or complex that traditional data processing application software is inadequate to deal with them.</p></li>
<li><p>Data analysis requires massively parallel software running on several servers.</p></li>
<li><p><strong>Volume, Variety, Velocity, Variability and Veracity</strong> describe Big Data properties.</p></li>
</ul>
<p><img alt="https://github.com/veekaybee/data-lake-talk/" src="_images/bigdata.png" /></p>
<p><img alt="Hadoop Logo" src="_images/hadoop.png" /></p>
<ul class="simple">
<li><p>Framework for running applications on large cluster.</p></li>
<li><p>The Hadoop framework transparently provides applications both reliability and data motion.</p></li>
<li><p>Hadoop implements the computational paradigm named <strong>Map/Reduce</strong>, where the application is divided into many small fragments of work, each of which may be executed or re-executed on any node in the cluster.</p></li>
<li><p>It provides a distributed file system (HDFS) that stores data on the compute nodes, providing very high aggregate bandwidth across the cluster.</p></li>
<li><p>Both MapReduce and the <strong>Hadoop Distributed File System</strong> are designed so that node failures are automatically handled by the framework.</p></li>
</ul>
<div class="section" id="hdfs">
<h2>HDFS<a class="headerlink" href="#hdfs" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>It is a distributed file systems.</p></li>
<li><p>HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware.</p></li>
<li><p>HDFS is suitable for applications that have large data sets.</p></li>
<li><p>HDFS provides interfaces to move applications closer to where the data is located. The computation is much more efficient when the size of the data set is huge.</p></li>
<li><p>HDFS consists of a single NameNode with a number of DataNodes which manage storage.</p></li>
<li><p>HDFS exposes a file system namespace and allows user data to be stored in files.</p>
<ol class="simple">
<li><p>A file is split by the NameNode into blocks stored in DataNodes.</p></li>
<li><p>The <a class="reference external" href="http://svmass2.mass.uhb.fr:50070">NameNode</a> executes operations like opening, closing, and renaming files and directories.</p></li>
<li><p>The <a class="reference external" href="http://svmass2.mass.uhb.fr:50090/status.html">Secondary NameNode</a> stores information from <strong>NameNode</strong>.</p></li>
<li><p>The <strong>DataNodes</strong> manage perform block creation, deletion, and replication upon instruction from the NameNode.</p></li>
<li><p>The placement of replicas is optimized for data reliability, availability, and network bandwidth utilization.</p></li>
<li><p>User data never flows through the NameNode.</p></li>
</ol>
</li>
<li><p>Files in HDFS are write-once and have strictly one writer at any time.</p></li>
<li><p>The DataNode has no knowledge about HDFS files.</p></li>
</ul>
</div>
<div class="section" id="accessibility">
<h2>Accessibility<a class="headerlink" href="#accessibility" title="Permalink to this headline">¶</a></h2>
<p>All <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html">HDFS commands</a>  are invoked by the bin/hdfs Java script:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs <span class="o">[</span>SHELL_OPTIONS<span class="o">]</span> COMMAND <span class="o">[</span>GENERIC_OPTIONS<span class="o">]</span> <span class="o">[</span>COMMAND_OPTIONS<span class="o">]</span>
</pre></div>
</div>
</div>
<div class="section" id="manage-files-and-directories">
<h2>Manage files and directories<a class="headerlink" href="#manage-files-and-directories" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs dfs -ls -h -R <span class="c1"># Recursively list subdirectories with human-readable file sizes.</span>
hdfs dfs -cp  <span class="c1"># Copy files from source to destination</span>
hdfs dfs -mv  <span class="c1"># Move files from source to destination</span>
hdfs dfs -mkdir /foodir <span class="c1"># Create a directory named /foodir	</span>
hdfs dfs -rmr /foodir   <span class="c1"># Remove a directory named /foodir	</span>
hdfs dfs -cat /foodir/myfile.txt <span class="c1">#View the contents of a file named /foodir/myfile.txt	</span>
</pre></div>
</div>
</div>
<div class="section" id="transfer-between-nodes">
<h2>Transfer between nodes<a class="headerlink" href="#transfer-between-nodes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="put">
<h3>put<a class="headerlink" href="#put" title="Permalink to this headline">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs fs -put <span class="o">[</span>-f<span class="o">]</span> <span class="o">[</span>-p<span class="o">]</span> <span class="o">[</span>-l<span class="o">]</span> <span class="o">[</span>-d<span class="o">]</span> <span class="o">[</span> - <span class="p">|</span> &lt;localsrc1&gt; .. <span class="o">]</span>. &lt;dst&gt;
</pre></div>
</div>
<p>Copy single src, or multiple srcs from local file system to the destination file system.</p>
<p>Options:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-p : Preserves rights and modification times.
-f : Overwrites the destination if it already exists.
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs fs -put localfile /user/hadoop/hadoopfile
hdfs fs -put -f localfile1 localfile2 /user/hadoop/hadoopdir
</pre></div>
</div>
<p>Similar to the fs -put command</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">moveFromLocal</span></code> : to delete the source localsrc after copy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copyFromLocal</span></code> : source is restricted to a local file</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copyToLocal</span></code> : destination is restricted to a local file</p></li>
</ul>
<p><img alt="hdfs blocks" src="_images/hdfs-fonctionnement.jpg" /></p>
<p>The Name Node is not in the data path. The Name Node only provides the map of where data is and where data should go in the cluster (file system metadata).</p>
</div>
</div>
<div class="section" id="hadoop-cluster">
<h2>Hadoop cluster<a class="headerlink" href="#hadoop-cluster" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>8 computers: sve1 -&gt; sve9</p></li>
</ul>
<div class="section" id="namenode-web-interface-hdfs-layer">
<h3>NameNode Web Interface (HDFS layer)<a class="headerlink" href="#namenode-web-interface-hdfs-layer" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://svmass2.mass.uhb.fr:50070">http://svmass2.mass.uhb.fr:50070</a></p>
<p>The name node web UI shows you a cluster summary including information about total/remaining capacity, live and dead nodes. Additionally, it allows you to browse the HDFS namespace and view the contents of its files in the web browser. It also gives access to the local machine’s Hadoop log files.</p>
</div>
<div class="section" id="secondary-namenode-information">
<h3>Secondary Namenode Information.<a class="headerlink" href="#secondary-namenode-information" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://svmass2.mass.uhb.fr:50090/">http://svmass2.mass.uhb.fr:50090/</a></p>
</div>
<div class="section" id="datanode-information">
<h3>Datanode Information.<a class="headerlink" href="#datanode-information" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://svpe1.mass.uhb.fr:50075/">http://svpe1.mass.uhb.fr:50075/</a></p></li>
<li><p><a class="reference external" href="http://svpe2.mass.uhb.fr:50075/">http://svpe2.mass.uhb.fr:50075/</a></p></li>
<li><p>…</p></li>
<li><p><a class="reference external" href="http://svpe8.mass.uhb.fr:50075/">http://svpe8.mass.uhb.fr:50075/</a></p></li>
<li><p><a class="reference external" href="http://svpe9.mass.uhb.fr:50075/">http://svpe9.mass.uhb.fr:50075/</a></p></li>
</ul>
<p>To do following hands on you can switch to <a class="reference external" href="https://jupyterlab.readthedocs.io">JupyterLab</a>.</p>
<p>Just go to this following address <a class="reference external" href="http://localhost:9000/lab">http://localhost:9000/lab</a></p>
<ul class="simple">
<li><p>Check that your HDFS home directory required to execute MapReduce jobs exists:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -ls /user/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Type the following commands:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -ls
hdfs dfs -ls /
hdfs dfs -mkdir <span class="nb">test</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a local file user.txt containing your name and the date:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># echo &quot;FirstName LastName&quot; &gt; user.txt</span>
<span class="c1"># echo `date` &gt;&gt; user.txt </span>
<span class="c1"># cat user.txt</span>
</pre></div>
</div>
</div>
</div>
<p>Copy it on  HDFS :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -put user.txt
</pre></div>
</div>
<p>Check with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -ls -R 
hdfs dfs -cat user.txt 
hdfs dfs -tail user.txt 
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -put user.txt</span>
<span class="c1"># hdfs dfs -ls -R /user/navaro_p/</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -cat user.txt</span>
</pre></div>
</div>
</div>
</div>
<p>Remove the file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -rm user.txt
</pre></div>
</div>
<p>Put it again on HDFS and move to books directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -copyFromLocal user.txt
hdfs dfs -mv user.txt books/user.txt
hdfs dfs -ls -R -h
</pre></div>
</div>
<p>Copy user.txt to hello.txt and remove it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -cp books/user.txt books/hello.txt
hdfs dfs -count -h /user/<span class="nv">$USER</span>
hdfs dfs -rm books/user.txt
</pre></div>
</div>
</div>
</div>
<div class="section" id="hands-on-practice">
<h2>Hands-on practice:<a class="headerlink" href="#hands-on-practice" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Create a directory <code class="docutils literal notranslate"><span class="pre">files</span></code> in HDFS.</p></li>
<li><p>List the contents of a directory /.</p></li>
<li><p>Upload the file today.txt in HDFS.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>date &gt; today.txt
whoami &gt;&gt; today.txt
</pre></div>
</div>
<ol class="simple">
<li><p>Display contents of file <code class="docutils literal notranslate"><span class="pre">today.txt</span></code></p></li>
<li><p>Copy <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> file from source to <code class="docutils literal notranslate"><span class="pre">files</span></code> directory.</p></li>
<li><p>Copy file <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code> from/To Local file system to HDFS</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>jps &gt; jps.txt
</pre></div>
</div>
<ol class="simple">
<li><p>Move file <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code> from source to <code class="docutils literal notranslate"><span class="pre">files</span></code>.</p></li>
<li><p>Remove file <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> from home directory in HDFS.</p></li>
<li><p>Display last few lines of <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code>.</p></li>
<li><p>Display the help of <code class="docutils literal notranslate"><span class="pre">du</span></code> command and show the total amount of space in a human-readable fashion used by your home hdfs directory.</p></li>
<li><p>Display the help of <code class="docutils literal notranslate"><span class="pre">df</span></code> command and show the total amount of space available in the filesystem in a human-readable fashion.</p></li>
<li><p>With <code class="docutils literal notranslate"><span class="pre">chmod</span></code> change the rights of <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> file. I has to be readable and writeable only by you.</p></li>
</ol>
</div>
<div class="section" id="yarn">
<h2>YARN<a class="headerlink" href="#yarn" title="Permalink to this headline">¶</a></h2>
<p><em>YARN takes care of resource management and job scheduling/monitoring.</em></p>
<ul class="simple">
<li><p>The <strong>ResourceManager</strong> is the ultimate authority that arbitrates resources among all the applications in the system. It has two components: <strong>Scheduler</strong> and <strong>ApplicationsManager</strong>.</p></li>
<li><p>The <strong>NodeManager</strong> is the per-machine framework agent who is responsible for <strong>Containers</strong>, monitoring their resource usage (cpu, memory, disk, network) and reporting the same to the <strong>ResourceManager/Scheduler</strong>.</p></li>
</ul>
<p>The per-application <strong>ApplicationMaster</strong> negotiates resources from the ResourceManager and working with the NodeManager(s) to execute and monitor the tasks.</p>
<ul class="simple">
<li><p>The <strong>Scheduler</strong> is responsible for allocating resources to the applications.</p></li>
<li><p>The <strong>ApplicationsManager</strong> is responsible for accepting job-submissions, tracking their status and monitoring for progress.</p></li>
</ul>
<p><img alt="Yarn in Hadoop documentation" src="_images/yarn_architecture.png" />
Source: <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif">http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif</a></p>
<div class="section" id="yarn-web-interface">
<h3>Yarn Web Interface<a class="headerlink" href="#yarn-web-interface" title="Permalink to this headline">¶</a></h3>
<p>The JobTracker web UI provides information about general job statistics of the Hadoop cluster, running/completed/failed jobs and a job history log file. It also gives access to the ‘‘local machine’s’’ Hadoop log files (the machine on which the web UI is running on).</p>
<ul class="simple">
<li><p>All Applications <a class="reference external" href="http://svmass2.mass.uhb.fr:8088">http://svmass2.mass.uhb.fr:8088</a></p></li>
</ul>
</div>
</div>
<div class="section" id="wordcount-example">
<h2>WordCount Example<a class="headerlink" href="#wordcount-example" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://wiki.apache.org/hadoop/WordCount">Worcount example</a> is implemented in Java and it is the example of <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Hadoop MapReduce Tutorial</a></p>
<p>Let’s create some files with lorem python package</p>
<ul class="simple">
<li><p>Make input directory in your HDFS home directory required to execute MapReduce jobs:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs dfs -mkdir -p /user/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/input
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">-p</span></code> flag force the directory creation even if it already exists.</p>
<div class="section" id="exercise">
<h3>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Copy all necessary files in HDFS system.</p></li>
<li><p>Run the Java example using the command</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hadoop jar /export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /user/you/input /user/you/output
</pre></div>
</div>
<ul class="simple">
<li><p>Remove the output directory and try to use yarn</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yarn jar /export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /user/you/input /user/you/output
</pre></div>
</div>
<ul class="simple">
<li><p>Connect to the <a class="reference external" href="http://svmass2.mass.uhb.fr:8088/cluster">Yarn web user interface</a> and read the logs carefully.</p></li>
</ul>
</div>
</div>
<div class="section" id="deploying-the-mapreduce-python-code-on-hadoop">
<h2>Deploying the MapReduce Python code on Hadoop<a class="headerlink" href="#deploying-the-mapreduce-python-code-on-hadoop" title="Permalink to this headline">¶</a></h2>
<p>This Python must use the <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html">Hadoop Streaming API</a> to pass data between our Map and Reduce code via Python’s sys.stdin (standard input) and sys.stdout (standard output).</p>
</div>
<div class="section" id="map">
<h2>Map<a class="headerlink" href="#map" title="Permalink to this headline">¶</a></h2>
<p>The following Python code read data from sys.stdin, split it into words and output a list of lines mapping words to their (intermediate) counts to sys.stdout. For every word it outputs <word> 1 tuples immediately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">file</span> <span class="n">mapper</span><span class="o">.</span><span class="n">py</span>
<span class="c1">#!/usr/bin/env python</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># input comes from standard input</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="c1"># remove leading and trailing whitespace</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>   <span class="c1"># strip punctuation </span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span> <span class="c1"># split the line into words</span>
        <span class="c1"># write the results to standard output;</span>
        <span class="c1"># what we output here will be the input for the</span>
        <span class="c1"># Reduce step, i.e. the input for reducer.py</span>
        <span class="c1"># tab-delimited; the trivial word count is 1</span>
        <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="s1"> 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The python script must be executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>chmod +x mapper.py 
</pre></div>
</div>
<p>Try to run in a terminal with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat sample01.txt <span class="p">|</span> ./mapper.py <span class="p">|</span> sort
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./mapper.py &lt; sample01.txt <span class="p">|</span> sort
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># chmod +x mapper.py</span>
<span class="c1"># cat sample01.txt | ./mapper.py | sort</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reduce">
<h2>Reduce<a class="headerlink" href="#reduce" title="Permalink to this headline">¶</a></h2>
<p>The following code reads the results of <a class="reference external" href="http://mapper.py">mapper.py</a> and sum the occurrences of each word to a final count, and then output its results to sys.stdout.
Remember that Hadoop sorts map output so it is easier to count words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">file</span> <span class="n">reducer</span><span class="o">.</span><span class="n">py</span>
<span class="c1">#!/usr/bin/env python</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">current_word</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">current_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">word</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    
    <span class="c1"># parse the input we got from mapper.py</span>
    <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># convert count (currently a string) to int</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="c1"># count was not a number, so silently</span>
        <span class="c1"># ignore/discard this line</span>
        <span class="k">continue</span>

    <span class="c1"># this IF-switch only works because Hadoop sorts map output</span>
    <span class="c1"># by key (here: word) before it is passed to the reducer</span>
    <span class="k">if</span> <span class="n">current_word</span> <span class="o">==</span> <span class="n">word</span><span class="p">:</span>
        <span class="n">current_count</span> <span class="o">+=</span> <span class="n">count</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">current_word</span><span class="p">:</span>
            <span class="c1"># write result to sys.stdout</span>
            <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">current_count</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">current_word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">current_count</span> <span class="o">=</span> <span class="n">count</span>
        <span class="n">current_word</span> <span class="o">=</span> <span class="n">word</span>

<span class="c1"># do not forget to output the last word if needed!</span>
<span class="k">if</span> <span class="n">current_word</span> <span class="o">==</span> <span class="n">word</span><span class="p">:</span>
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">current_count</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">current_word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As mapper the python script must be executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>chmod +x reducer.py 
</pre></div>
</div>
<p>Try to run in a terminal with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat sample.txt <span class="p">|</span> ./mapper.py <span class="p">|</span> sort <span class="p">|</span> ./reducer.py <span class="p">|</span> sort
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./mapper.py &lt; sample01.txt <span class="p">|</span> sort <span class="p">|</span> ./reducer.py <span class="p">|</span> sort
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># chmod +x reducer.py </span>
<span class="c1"># ./mapper.py &lt; sample01.txt | sort | ./reducer.py | sort</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="execution-on-hadoop-cluster">
<h2>Execution on Hadoop cluster<a class="headerlink" href="#execution-on-hadoop-cluster" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Copy all files to HDFS cluster</p></li>
<li><p>Run the WordCount MapReduce</p></li>
</ul>
<p>Before to run the following command you need to replace the path to the python executable. To print this path you can use the command</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">which</span> <span class="n">python</span>
</pre></div>
</div>
<p>You should get</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">tljh</span><span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span>
</pre></div>
</div>
<p>So replace the line</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>
</pre></div>
</div>
<p>by</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/opt/tljh/user/bin/python</span>
</pre></div>
</div>
<p>in both files <a class="reference external" href="http://mapper.py">mapper.py</a> and <a class="reference external" href="http://reducer.py">reducer.py</a></p>
<p>Ensure that the output directory does not exist by removing it</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span> <span class="n">dfs</span> <span class="o">-</span><span class="n">rm</span> <span class="o">-</span><span class="n">r</span> <span class="n">output</span>
</pre></div>
</div>
<p>Use the hadoop streaming library to read files on hdfs and redirect data to standard input, use your python scripts
to process the data and write the result on hdfs directory named output :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>hadoop jar /export/hadoop-2.7.6/share/hadoop/tools/lib/hadoop-streaming-2.7.6.jar \
-input input/*.txt -output output \
-file ${PWD}/mapper.py -mapper ${PWD}/mapper.py \
-file ${PWD}/reducer.py -reducer ${PWD}/reducer.py
</pre></div>
</div>
<p>Check the results with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span> <span class="n">dfs</span> <span class="o">-</span><span class="n">cat</span> <span class="n">output</span><span class="o">/*</span>
</pre></div>
</div>
<p>You can avoid these long lines commands by editing a Makefile</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>%%file Makefile

HADOOP_VERSION=2.7.6
HADOOP_HOME=/export/hadoop-${HADOOP_VERSION}
HADOOP_TOOLS=${HADOOP_HOME}/share/hadoop/tools/lib
HDFS_DIR=/user/${USER}
 
SAMPLES = sample01.txt sample02.txt sample03.txt sample04.txt

copy_to_hdfs: ${SAMPLES}
	hdfs dfs -mkdir -p ${HDFS_DIR}/input
	hdfs dfs -put $^ ${HDFS_DIR}/input

run_with_hadoop: 
	hadoop jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \
    -file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \
    -file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \
    -input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-hadoop

run_with_yarn: 
	yarn jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \
	-file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \
	-file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \
	-input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-yarn
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -rm -r input  # remove input directory</span>
<span class="c1"># make copy_to_hdfs # copy sample files to hdfs</span>
<span class="c1"># hdfs dfs -ls input # list files on hdfs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -rm -r -f output-hadoop # Remove output directory on hdfs</span>
<span class="c1"># make run_with_hadoop  # Run the hadoop streaming map reduce process</span>
<span class="c1"># hdfs dfs -cat output-hadoop/*  # Display results</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pnavaro/big-data",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "big-data"
        },
        kernelOptions: {
            kernelName: "big-data",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'big-data'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="12-UnixCommands.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Basic Commands in the Unix Shell</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="14-FileFormats.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File Formats</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Pierre Navaro<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>