

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Hadoop &#8212; Python tools for Big data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '13-Hadoop';</script>
    <link rel="canonical" href="https://pnavaro.github.io/big-data/13-Hadoop.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="File Formats" href="14-FileFormats.html" />
    <link rel="prev" title="Basic Commands in the Unix Shell" href="12-UnixCommands.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo_ENSAI.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo_ENSAI.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-GitBasics.html">Git basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-JupyterQuickStart.html">Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-WordCount.html">Wordcount</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-MapReduce.html">Map Reduce</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-ParallelComputation.html">Parallel Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-AsynchronousProcessing.html">Asynchronous Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-DaskDelayed.html">Dask</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-DaskBag.html">Dask bag</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-PandasSeries.html">Pandas Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-PandaDataframes.html">Pandas Dataframes</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-UnixCommands.html">Basic Commands in the Unix Shell</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Hadoop</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-FileFormats.html">File Formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="15-PySpark.html">PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-DaskDataframes.html">Dask Dataframes</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-SparkDataFrames.html">Spark DataFrames</a></li>
<li class="toctree-l1"><a class="reference internal" href="18-NYCTaxiCabTripDask.html">Dask dataframes on HDFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="19-NYCTaxiCabTripSpark.html">Spark dataframes on HDFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="20-NYCFlightsSpark.html">NYC Flights data analysis with Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="21-NYCFLights2013Spark.html">NYC Flights data 2013 with Weather data</a></li>
<li class="toctree-l1"><a class="reference internal" href="22-SparkExercises.html">Spark exercises</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pnavaro/big-data/master?urlpath=tree/notebooks/13-Hadoop.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pnavaro/big-data/blob/master/notebooks/13-Hadoop.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pnavaro/big-data" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pnavaro/big-data/edit/master/notebooks/13-Hadoop.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pnavaro/big-data/issues/new?title=Issue%20on%20page%20%2F13-Hadoop.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/13-Hadoop.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Hadoop</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accessibility">Accessibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manage-files-and-directories">Manage files and directories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-between-nodes">Transfer between nodes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#put">put</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hadoop-cluster">Hadoop cluster</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#namenode-web-interface-hdfs-layer">NameNode Web Interface (HDFS layer)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#secondary-namenode-information">Secondary Namenode Information.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#datanode-information">Datanode Information.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on-practice">Hands-on practice:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yarn">YARN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yarn-web-interface">Yarn Web Interface</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcount-example">WordCount Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploying-the-mapreduce-python-code-on-hadoop">Deploying the MapReduce Python code on Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map">Map</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce">Reduce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#execution-on-hadoop-cluster">Execution on Hadoop cluster</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="hadoop">
<h1>Hadoop<a class="headerlink" href="#hadoop" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Data sets that are so large or complex that traditional data processing application software is inadequate to deal with them.</p></li>
<li><p>Data analysis requires massively parallel software running on several servers.</p></li>
<li><p><strong>Volume, Variety, Velocity, Variability and Veracity</strong> describe Big Data properties.</p></li>
</ul>
<p><img alt="https://github.com/veekaybee/data-lake-talk/" src="_images/bigdata.png" /></p>
<p><img alt="Hadoop Logo" src="_images/hadoop.png" /></p>
<ul class="simple">
<li><p>Framework for running applications on large cluster.</p></li>
<li><p>The Hadoop framework transparently provides applications both reliability and data motion.</p></li>
<li><p>Hadoop implements the computational paradigm named <strong>Map/Reduce</strong>, where the application is divided into many small fragments of work, each of which may be executed or re-executed on any node in the cluster.</p></li>
<li><p>It provides a distributed file system (HDFS) that stores data on the compute nodes, providing very high aggregate bandwidth across the cluster.</p></li>
<li><p>Both MapReduce and the <strong>Hadoop Distributed File System</strong> are designed so that node failures are automatically handled by the framework.</p></li>
</ul>
<section id="hdfs">
<h2>HDFS<a class="headerlink" href="#hdfs" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>It is a distributed file systems.</p></li>
<li><p>HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware.</p></li>
<li><p>HDFS is suitable for applications that have large data sets.</p></li>
<li><p>HDFS provides interfaces to move applications closer to where the data is located. The computation is much more efficient when the size of the data set is huge.</p></li>
<li><p>HDFS consists of a single NameNode with a number of DataNodes which manage storage.</p></li>
<li><p>HDFS exposes a file system namespace and allows user data to be stored in files.</p>
<ol class="arabic simple">
<li><p>A file is split by the NameNode into blocks stored in DataNodes.</p></li>
<li><p>The <a class="reference external" href="http://svmass2.mass.uhb.fr:50070">NameNode</a> executes operations like opening, closing, and renaming files and directories.</p></li>
<li><p>The <a class="reference external" href="http://svmass2.mass.uhb.fr:50090/status.html">Secondary NameNode</a> stores information from <strong>NameNode</strong>.</p></li>
<li><p>The <strong>DataNodes</strong> manage perform block creation, deletion, and replication upon instruction from the NameNode.</p></li>
<li><p>The placement of replicas is optimized for data reliability, availability, and network bandwidth utilization.</p></li>
<li><p>User data never flows through the NameNode.</p></li>
</ol>
</li>
<li><p>Files in HDFS are write-once and have strictly one writer at any time.</p></li>
<li><p>The DataNode has no knowledge about HDFS files.</p></li>
</ul>
</section>
<section id="accessibility">
<h2>Accessibility<a class="headerlink" href="#accessibility" title="Permalink to this heading">#</a></h2>
<p>All <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html">HDFS commands</a>  are invoked by the bin/hdfs Java script:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span><span class="o">[</span>SHELL_OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>GENERIC_OPTIONS<span class="o">]</span><span class="w"> </span><span class="o">[</span>COMMAND_OPTIONS<span class="o">]</span>
</pre></div>
</div>
</section>
<section id="manage-files-and-directories">
<h2>Manage files and directories<a class="headerlink" href="#manage-files-and-directories" title="Permalink to this heading">#</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls<span class="w"> </span>-h<span class="w"> </span>-R<span class="w"> </span><span class="c1"># Recursively list subdirectories with human-readable file sizes.</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-cp<span class="w">  </span><span class="c1"># Copy files from source to destination</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-mv<span class="w">  </span><span class="c1"># Move files from source to destination</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-mkdir<span class="w"> </span>/foodir<span class="w"> </span><span class="c1"># Create a directory named /foodir	</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-rmr<span class="w"> </span>/foodir<span class="w">   </span><span class="c1"># Remove a directory named /foodir	</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-cat<span class="w"> </span>/foodir/myfile.txt<span class="w"> </span><span class="c1">#View the contents of a file named /foodir/myfile.txt	</span>
</pre></div>
</div>
</section>
<section id="transfer-between-nodes">
<h2>Transfer between nodes<a class="headerlink" href="#transfer-between-nodes" title="Permalink to this heading">#</a></h2>
<section id="put">
<h3>put<a class="headerlink" href="#put" title="Permalink to this heading">#</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>fs<span class="w"> </span>-put<span class="w"> </span><span class="o">[</span>-f<span class="o">]</span><span class="w"> </span><span class="o">[</span>-p<span class="o">]</span><span class="w"> </span><span class="o">[</span>-l<span class="o">]</span><span class="w"> </span><span class="o">[</span>-d<span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>-<span class="w"> </span><span class="p">|</span><span class="w"> </span>&lt;localsrc1&gt;<span class="w"> </span>..<span class="w"> </span><span class="o">]</span>.<span class="w"> </span>&lt;dst&gt;
</pre></div>
</div>
<p>Copy single src, or multiple srcs from local file system to the destination file system.</p>
<p>Options:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-p : Preserves rights and modification times.
-f : Overwrites the destination if it already exists.
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>fs<span class="w"> </span>-put<span class="w"> </span>localfile<span class="w"> </span>/user/hadoop/hadoopfile
hdfs<span class="w"> </span>fs<span class="w"> </span>-put<span class="w"> </span>-f<span class="w"> </span>localfile1<span class="w"> </span>localfile2<span class="w"> </span>/user/hadoop/hadoopdir
</pre></div>
</div>
<p>Similar to the fs -put command</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">moveFromLocal</span></code> : to delete the source localsrc after copy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copyFromLocal</span></code> : source is restricted to a local file</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copyToLocal</span></code> : destination is restricted to a local file</p></li>
</ul>
<p><img alt="hdfs blocks" src="_images/hdfs-fonctionnement.jpg" /></p>
<p>The Name Node is not in the data path. The Name Node only provides the map of where data is and where data should go in the cluster (file system metadata).</p>
</section>
</section>
<section id="hadoop-cluster">
<h2>Hadoop cluster<a class="headerlink" href="#hadoop-cluster" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>8 computers: sve1 -&gt; sve9</p></li>
</ul>
<section id="namenode-web-interface-hdfs-layer">
<h3>NameNode Web Interface (HDFS layer)<a class="headerlink" href="#namenode-web-interface-hdfs-layer" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="http://svmass2.mass.uhb.fr:50070">http://svmass2.mass.uhb.fr:50070</a></p>
<p>The name node web UI shows you a cluster summary including information about total/remaining capacity, live and dead nodes. Additionally, it allows you to browse the HDFS namespace and view the contents of its files in the web browser. It also gives access to the local machine’s Hadoop log files.</p>
</section>
<section id="secondary-namenode-information">
<h3>Secondary Namenode Information.<a class="headerlink" href="#secondary-namenode-information" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="http://svmass2.mass.uhb.fr:50090/">http://svmass2.mass.uhb.fr:50090/</a></p>
</section>
<section id="datanode-information">
<h3>Datanode Information.<a class="headerlink" href="#datanode-information" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://svpe1.mass.uhb.fr:50075/">http://svpe1.mass.uhb.fr:50075/</a></p></li>
<li><p><a class="reference external" href="http://svpe2.mass.uhb.fr:50075/">http://svpe2.mass.uhb.fr:50075/</a></p></li>
<li><p>…</p></li>
<li><p><a class="reference external" href="http://svpe8.mass.uhb.fr:50075/">http://svpe8.mass.uhb.fr:50075/</a></p></li>
<li><p><a class="reference external" href="http://svpe9.mass.uhb.fr:50075/">http://svpe9.mass.uhb.fr:50075/</a></p></li>
</ul>
<p>To do following hands on you can switch to <a class="reference external" href="https://jupyterlab.readthedocs.io">JupyterLab</a>.</p>
<p>Just go to this following address <a class="reference external" href="http://localhost:9000/lab">http://localhost:9000/lab</a></p>
<ul class="simple">
<li><p>Check that your HDFS home directory required to execute MapReduce jobs exists:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls<span class="w"> </span>/user/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Type the following commands:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls
hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls<span class="w"> </span>/
hdfs<span class="w"> </span>dfs<span class="w"> </span>-mkdir<span class="w"> </span><span class="nb">test</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create a local file user.txt containing your name and the date:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># echo &quot;FirstName LastName&quot; &gt; user.txt</span>
<span class="c1"># echo `date` &gt;&gt; user.txt </span>
<span class="c1"># cat user.txt</span>
</pre></div>
</div>
</div>
</div>
<p>Copy it on  HDFS :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-put<span class="w"> </span>user.txt
</pre></div>
</div>
<p>Check with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls<span class="w"> </span>-R<span class="w"> </span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-cat<span class="w"> </span>user.txt<span class="w"> </span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-tail<span class="w"> </span>user.txt<span class="w"> </span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -put user.txt</span>
<span class="c1"># hdfs dfs -ls -R /user/navaro_p/</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -cat user.txt</span>
</pre></div>
</div>
</div>
</div>
<p>Remove the file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-rm<span class="w"> </span>user.txt
</pre></div>
</div>
<p>Put it again on HDFS and move to books directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-copyFromLocal<span class="w"> </span>user.txt
hdfs<span class="w"> </span>dfs<span class="w"> </span>-mv<span class="w"> </span>user.txt<span class="w"> </span>books/user.txt
hdfs<span class="w"> </span>dfs<span class="w"> </span>-ls<span class="w"> </span>-R<span class="w"> </span>-h
</pre></div>
</div>
<p>Copy user.txt to hello.txt and remove it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-cp<span class="w"> </span>books/user.txt<span class="w"> </span>books/hello.txt
hdfs<span class="w"> </span>dfs<span class="w"> </span>-count<span class="w"> </span>-h<span class="w"> </span>/user/<span class="nv">$USER</span>
hdfs<span class="w"> </span>dfs<span class="w"> </span>-rm<span class="w"> </span>books/user.txt
</pre></div>
</div>
</section>
</section>
<section id="hands-on-practice">
<h2>Hands-on practice:<a class="headerlink" href="#hands-on-practice" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Create a directory <code class="docutils literal notranslate"><span class="pre">files</span></code> in HDFS.</p></li>
<li><p>List the contents of a directory /.</p></li>
<li><p>Upload the file today.txt in HDFS.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>date<span class="w"> </span>&gt;<span class="w"> </span>today.txt
whoami<span class="w"> </span>&gt;&gt;<span class="w"> </span>today.txt
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Display contents of file <code class="docutils literal notranslate"><span class="pre">today.txt</span></code></p></li>
<li><p>Copy <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> file from source to <code class="docutils literal notranslate"><span class="pre">files</span></code> directory.</p></li>
<li><p>Copy file <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code> from/To Local file system to HDFS</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>jps<span class="w"> </span>&gt;<span class="w"> </span>jps.txt
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li><p>Move file <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code> from source to <code class="docutils literal notranslate"><span class="pre">files</span></code>.</p></li>
<li><p>Remove file <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> from home directory in HDFS.</p></li>
<li><p>Display last few lines of <code class="docutils literal notranslate"><span class="pre">jps.txt</span></code>.</p></li>
<li><p>Display the help of <code class="docutils literal notranslate"><span class="pre">du</span></code> command and show the total amount of space in a human-readable fashion used by your home hdfs directory.</p></li>
<li><p>Display the help of <code class="docutils literal notranslate"><span class="pre">df</span></code> command and show the total amount of space available in the filesystem in a human-readable fashion.</p></li>
<li><p>With <code class="docutils literal notranslate"><span class="pre">chmod</span></code> change the rights of <code class="docutils literal notranslate"><span class="pre">today.txt</span></code> file. I has to be readable and writeable only by you.</p></li>
</ol>
</section>
<section id="yarn">
<h2>YARN<a class="headerlink" href="#yarn" title="Permalink to this heading">#</a></h2>
<p><em>YARN takes care of resource management and job scheduling/monitoring.</em></p>
<ul class="simple">
<li><p>The <strong>ResourceManager</strong> is the ultimate authority that arbitrates resources among all the applications in the system. It has two components: <strong>Scheduler</strong> and <strong>ApplicationsManager</strong>.</p></li>
<li><p>The <strong>NodeManager</strong> is the per-machine framework agent who is responsible for <strong>Containers</strong>, monitoring their resource usage (cpu, memory, disk, network) and reporting the same to the <strong>ResourceManager/Scheduler</strong>.</p></li>
</ul>
<p>The per-application <strong>ApplicationMaster</strong> negotiates resources from the ResourceManager and working with the NodeManager(s) to execute and monitor the tasks.</p>
<ul class="simple">
<li><p>The <strong>Scheduler</strong> is responsible for allocating resources to the applications.</p></li>
<li><p>The <strong>ApplicationsManager</strong> is responsible for accepting job-submissions, tracking their status and monitoring for progress.</p></li>
</ul>
<p><img alt="Yarn in Hadoop documentation" src="_images/yarn_architecture.png" />
Source: <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif">http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif</a></p>
<section id="yarn-web-interface">
<h3>Yarn Web Interface<a class="headerlink" href="#yarn-web-interface" title="Permalink to this heading">#</a></h3>
<p>The JobTracker web UI provides information about general job statistics of the Hadoop cluster, running/completed/failed jobs and a job history log file. It also gives access to the ‘‘local machine’s’’ Hadoop log files (the machine on which the web UI is running on).</p>
<ul class="simple">
<li><p>All Applications <a class="reference external" href="http://svmass2.mass.uhb.fr:8088">http://svmass2.mass.uhb.fr:8088</a></p></li>
</ul>
</section>
</section>
<section id="wordcount-example">
<h2>WordCount Example<a class="headerlink" href="#wordcount-example" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference external" href="https://wiki.apache.org/hadoop/WordCount">Worcount example</a> is implemented in Java and it is the example of <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Hadoop MapReduce Tutorial</a></p>
<p>Let’s create some files with lorem python package</p>
<ul class="simple">
<li><p>Make input directory in your HDFS home directory required to execute MapReduce jobs:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hdfs<span class="w"> </span>dfs<span class="w"> </span>-mkdir<span class="w"> </span>-p<span class="w"> </span>/user/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/input
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">-p</span></code> flag force the directory creation even if it already exists.</p>
<section id="exercise">
<h3>Exercise<a class="headerlink" href="#exercise" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Copy all necessary files in HDFS system.</p></li>
<li><p>Run the Java example using the command</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hadoop<span class="w"> </span>jar<span class="w"> </span>/export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar<span class="w"> </span>wordcount<span class="w"> </span>/user/you/input<span class="w"> </span>/user/you/output
</pre></div>
</div>
<ul class="simple">
<li><p>Remove the output directory and try to use yarn</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>yarn<span class="w"> </span>jar<span class="w"> </span>/export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar<span class="w"> </span>wordcount<span class="w"> </span>/user/you/input<span class="w"> </span>/user/you/output
</pre></div>
</div>
<ul class="simple">
<li><p>Connect to the <a class="reference external" href="http://svmass2.mass.uhb.fr:8088/cluster">Yarn web user interface</a> and read the logs carefully.</p></li>
</ul>
</section>
</section>
<section id="deploying-the-mapreduce-python-code-on-hadoop">
<h2>Deploying the MapReduce Python code on Hadoop<a class="headerlink" href="#deploying-the-mapreduce-python-code-on-hadoop" title="Permalink to this heading">#</a></h2>
<p>This Python must use the <a class="reference external" href="http://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html">Hadoop Streaming API</a> to pass data between our Map and Reduce code via Python’s sys.stdin (standard input) and sys.stdout (standard output).</p>
</section>
<section id="map">
<h2>Map<a class="headerlink" href="#map" title="Permalink to this heading">#</a></h2>
<p>The following Python code read data from sys.stdin, split it into words and output a list of lines mapping words to their (intermediate) counts to sys.stdout. For every word it outputs <word> 1 tuples immediately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">file</span> <span class="n">mapper</span><span class="o">.</span><span class="n">py</span>
<span class="c1">#!/usr/bin/env python</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># input comes from standard input</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="c1"># remove leading and trailing whitespace</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>   <span class="c1"># strip punctuation </span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span> <span class="c1"># split the line into words</span>
        <span class="c1"># write the results to standard output;</span>
        <span class="c1"># what we output here will be the input for the</span>
        <span class="c1"># Reduce step, i.e. the input for reducer.py</span>
        <span class="c1"># tab-delimited; the trivial word count is 1</span>
        <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="s1"> 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The python script must be executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>chmod<span class="w"> </span>+x<span class="w"> </span>mapper.py<span class="w"> </span>
</pre></div>
</div>
<p>Try to run in a terminal with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>sample01.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>./mapper.py<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./mapper.py<span class="w"> </span>&lt;<span class="w"> </span>sample01.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># chmod +x mapper.py</span>
<span class="c1"># cat sample01.txt | ./mapper.py | sort</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="reduce">
<h2>Reduce<a class="headerlink" href="#reduce" title="Permalink to this heading">#</a></h2>
<p>The following code reads the results of <a class="reference external" href="http://mapper.py">mapper.py</a> and sum the occurrences of each word to a final count, and then output its results to sys.stdout.
Remember that Hadoop sorts map output so it is easier to count words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">file</span> <span class="n">reducer</span><span class="o">.</span><span class="n">py</span>
<span class="c1">#!/usr/bin/env python</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">current_word</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">current_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">word</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
    
    <span class="c1"># parse the input we got from mapper.py</span>
    <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># convert count (currently a string) to int</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="c1"># count was not a number, so silently</span>
        <span class="c1"># ignore/discard this line</span>
        <span class="k">continue</span>

    <span class="c1"># this IF-switch only works because Hadoop sorts map output</span>
    <span class="c1"># by key (here: word) before it is passed to the reducer</span>
    <span class="k">if</span> <span class="n">current_word</span> <span class="o">==</span> <span class="n">word</span><span class="p">:</span>
        <span class="n">current_count</span> <span class="o">+=</span> <span class="n">count</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">current_word</span><span class="p">:</span>
            <span class="c1"># write result to sys.stdout</span>
            <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">current_count</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">current_word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">current_count</span> <span class="o">=</span> <span class="n">count</span>
        <span class="n">current_word</span> <span class="o">=</span> <span class="n">word</span>

<span class="c1"># do not forget to output the last word if needed!</span>
<span class="k">if</span> <span class="n">current_word</span> <span class="o">==</span> <span class="n">word</span><span class="p">:</span>
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">current_count</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">current_word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As mapper the python script must be executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>chmod<span class="w"> </span>+x<span class="w"> </span>reducer.py<span class="w"> </span>
</pre></div>
</div>
<p>Try to run in a terminal with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>sample.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>./mapper.py<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span><span class="p">|</span><span class="w"> </span>./reducer.py<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./mapper.py<span class="w"> </span>&lt;<span class="w"> </span>sample01.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span><span class="p">|</span><span class="w"> </span>./reducer.py<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># chmod +x reducer.py </span>
<span class="c1"># ./mapper.py &lt; sample01.txt | sort | ./reducer.py | sort</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="execution-on-hadoop-cluster">
<h2>Execution on Hadoop cluster<a class="headerlink" href="#execution-on-hadoop-cluster" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Copy all files to HDFS cluster</p></li>
<li><p>Run the WordCount MapReduce</p></li>
</ul>
<p>Before to run the following command you need to replace the path to the python executable. To print this path you can use the command</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">which</span> <span class="n">python</span>
</pre></div>
</div>
<p>You should get</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">tljh</span><span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span>
</pre></div>
</div>
<p>So replace the line</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>
</pre></div>
</div>
<p>by</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/opt/tljh/user/bin/python</span>
</pre></div>
</div>
<p>in both files <a class="reference external" href="http://mapper.py">mapper.py</a> and <a class="reference external" href="http://reducer.py">reducer.py</a></p>
<p>Ensure that the output directory does not exist by removing it</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span> <span class="n">dfs</span> <span class="o">-</span><span class="n">rm</span> <span class="o">-</span><span class="n">r</span> <span class="n">output</span>
</pre></div>
</div>
<p>Use the hadoop streaming library to read files on hdfs and redirect data to standard input, use your python scripts
to process the data and write the result on hdfs directory named output :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>hadoop jar /export/hadoop-2.7.6/share/hadoop/tools/lib/hadoop-streaming-2.7.6.jar \
-input input/*.txt -output output \
-file ${PWD}/mapper.py -mapper ${PWD}/mapper.py \
-file ${PWD}/reducer.py -reducer ${PWD}/reducer.py
</pre></div>
</div>
<p>Check the results with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span> <span class="n">dfs</span> <span class="o">-</span><span class="n">cat</span> <span class="n">output</span><span class="o">/*</span>
</pre></div>
</div>
<p>You can avoid these long lines commands by editing a Makefile</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%file Makefile

HADOOP_VERSION=2.7.6
HADOOP_HOME=/export/hadoop-${HADOOP_VERSION}
HADOOP_TOOLS=${HADOOP_HOME}/share/hadoop/tools/lib
HDFS_DIR=/user/${USER}
 
SAMPLES = sample01.txt sample02.txt sample03.txt sample04.txt

copy_to_hdfs: ${SAMPLES}
	hdfs dfs -mkdir -p ${HDFS_DIR}/input
	hdfs dfs -put $^ ${HDFS_DIR}/input

run_with_hadoop: 
	hadoop jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \
    -file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \
    -file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \
    -input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-hadoop

run_with_yarn: 
	yarn jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \
	-file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \
	-file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \
	-input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-yarn
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -rm -r input  # remove input directory</span>
<span class="c1"># make copy_to_hdfs # copy sample files to hdfs</span>
<span class="c1"># hdfs dfs -ls input # list files on hdfs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%bash</span>
<span class="c1"># hdfs dfs -rm -r -f output-hadoop # Remove output directory on hdfs</span>
<span class="c1"># make run_with_hadoop  # Run the hadoop streaming map reduce process</span>
<span class="c1"># hdfs dfs -cat output-hadoop/*  # Display results</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pnavaro/big-data",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "big-data"
        },
        kernelOptions: {
            name: "big-data",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'big-data'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="12-UnixCommands.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Basic Commands in the Unix Shell</p>
      </div>
    </a>
    <a class="right-next"
       href="14-FileFormats.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File Formats</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accessibility">Accessibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manage-files-and-directories">Manage files and directories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-between-nodes">Transfer between nodes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#put">put</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hadoop-cluster">Hadoop cluster</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#namenode-web-interface-hdfs-layer">NameNode Web Interface (HDFS layer)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#secondary-namenode-information">Secondary Namenode Information.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#datanode-information">Datanode Information.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on-practice">Hands-on practice:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yarn">YARN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yarn-web-interface">Yarn Web Interface</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wordcount-example">WordCount Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploying-the-mapreduce-python-code-on-hadoop">Deploying the MapReduce Python code on Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map">Map</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce">Reduce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#execution-on-hadoop-cluster">Execution on Hadoop cluster</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pierre Navaro
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>