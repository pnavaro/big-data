name: book
on:
  push:
    branches:
      - master
jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Install pandoc
      run: |
        sudo apt-get -yq update
        sudo apt-get install -yq pandoc texlive-xetex texlive-fonts-extra graphviz
    - name: Checkout
      uses: actions/checkout@v2
      with:
        persist-credentials: false
    - name: Set up JDK 1.8
      uses: actions/setup-java@v1
      with:
        java-version: 1.8
    - name: Download Apache Spark
      uses: wei/wget@v1
      with:
        args: https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz
    - name: Install Apache Spark
      run: tar zxf spark-3.0.1-bin-hadoop2.7.tgz
    - name: Set SPARK_HOME
      run: echo "SPARK_HOME=/home/runner/spark-3.0.0-bin-hadoop2.7" >> $GITHUB_ENV
    - name: Install Miniconda and dependencies
      uses: conda-incubator/setup-miniconda@v2
      with:
        miniconda-version: "latest"
        activate-environment: big-data
        environment-file: environment.yml
    - name: Install jupyter-book
      shell: bash -l {0}
      run: |
        conda run -n big-data python -m ipykernel install --user --name big-data
        conda run -n base python -m pip install jupyter-book
    - name: Build the book
      shell: bash -l {0}
      run: conda run -n base jupyter-book build notebooks
    - name: "Install quarto bin"
      run: |
        curl -s https://api.github.com/repos/quarto-dev/quarto-cli/releases/latest | 
        grep "browser_download_url.*deb" | 
        cut -d '"' -f 4 |
        wget -i -O quarto.deb -
        sudo dpkg -i quarto.deb
    - name: Render quarto book
      shell: bash -l {0}
      run: |
        conda run -n base quarto render notebooks
    - name: GitHub Pages action
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./notebooks/_build/html

